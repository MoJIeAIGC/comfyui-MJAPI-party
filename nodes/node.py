import requests
from PIL import Image
from io import BytesIO
import base64
from torchvision import transforms
import numpy as np
import torch
import os
from comfy_api.input_impl.video_types import VideoFromFile

from .base import ImageConverter
from .config import ConfigManager
import random
# åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
config_manager = ConfigManager()


class DreaminaI2INode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                # "image": ("STRING", {"default": "https://pic.52112.com/180320/180320_17/Bl3t6ivHKZ_small.jpg"}),
                "prompt": ("STRING", {"default": "", "multiline": True}),
                "width": ("INT", {"default": 1024}),
                "height": ("INT", {"default": 1024}),
                "gpen": ("FLOAT", {"default": 0.4}),
                "skin": ("FLOAT", {"default": 0.3}),
                "skin_unifi": ("FLOAT", {"default": 0.0}),
                "gen_mode": (["creative", "reference", "reference_char"], {"default": "reference"}),
                "seed": ("INT", {"default": -1}),  # -1è¡¨ç¤ºéšæœº
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # ç”Ÿæˆå¼ æ•°
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("output",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/ImageCreat"

    def generate(self, image, prompt, width, height, gpen, skin, skin_unifi, gen_mode, seed, batch_size):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        # Convert input tensor to base64
        pil_image = ImageConverter.tensor2pil(image)
        buffered = BytesIO()
        pil_image.save(buffered, format="JPEG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }

        output_tensors = []

        for i in range(batch_size):  # batch_size=2 æ—¶è°ƒç”¨ä¸¤æ¬¡
            payload = {
                "model": "volc-pic-3.0",
                "req_key": "i2i_portrait_photo",
                "prompt": prompt,
                "width": width,
                "height": height,
                "gpen": gpen,
                "skin": skin,
                "skin_unifi": skin_unifi,
                "gen_mode": gen_mode,
                "seed": seed+i,  # é¿å…å®Œå…¨ä¸€æ ·
                "batch_size": 1,  
                "image_base64": img_base64
            }

            try:
                response = requests.post(oneapi_url, headers=headers, json=payload, timeout=120)
                # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
                if response.status_code != 200:
                    error_msg = ImageConverter.get_status_error_msg(response,1)
                    error_tensor = ImageConverter.create_error_image(error_msg)
                    output_tensors.append(error_tensor)
                    continue
                response.raise_for_status()
                result = response.json()
                img_base64_list = result.get('data', {}).get('binary_data_base64', [])

                if not img_base64_list:
                    raise ValueError("APIè¿”å›ç©ºå›¾åƒæ•°æ®.")

                # æ­£å¸¸æƒ…å†µä¸‹æ¯æ¬¡è¿”å›1å¼ 
                img_bytes = base64.b64decode(img_base64_list[0])
                img = Image.open(BytesIO(img_bytes)).convert("RGB")
                # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
                tensor_img = ImageConverter.pil2tensor(img)
                output_tensors.append(tensor_img)

                print(f"âœ… DreaminaI2INode ç¬¬{i+1}æ¬¡è°ƒç”¨æˆåŠŸ")

            except Exception as e:
                print(f"âŒ DreaminaI2INode é”™è¯¯(ç¬¬{i+1}æ¬¡): {str(e)}")
                error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
                output_tensors.append(error_tensor)

        return (torch.cat(output_tensors, dim=0),)  # è¿”å›(batch_size, H, W, 3)

class FluxProNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "seed": ("INT", {"default": -1}),
                "is_translation": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "aspect_ratio": (["default", "1:1", "3:4", "4:3", "9:16", "16:9"], {"default": "default"}),
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
            },
            "optional": {
                "image_input": ("IMAGE", {"default": None}),  # å¯é€‰çš„å›¾åƒè¾“å…¥
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/ImageCreat"

    def generate(self, prompt, seed, batch_size, image_input=None, is_translation=False, aspect_ratio="default"):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        print(f"Flux API URL: {oneapi_url}")  # æ‰“å°API URL

        # å¦‚æœæä¾›äº†å›¾åƒè¾“å…¥ï¼Œå°†å…¶è½¬æ¢ä¸ºbase64
        image_base64 = None
        if image_input is not None:
            try:
                pil_image = ImageConverter.tensor2pil(image_input)
                buffered = BytesIO()
                pil_image.save(buffered, format="JPEG")
                img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
                image_base64 = img_base64
            except Exception as e:
                print(f"å¤„ç†å›¾åƒå¤±è´¥: {e}")
                image_base64 = None

        def call_api(seed_override):
            payload = {
                "model": "flux-context-pro",
                "safety_tolerance":6,
                "prompt": prompt,
                "seed": int(seed_override),
                "is_translation": is_translation,  # ä¼ é€’ç¿»è¯‘æ¨¡å¼å‚æ•°
            }
            # å¦‚æœæœ‰å›¾åƒè¾“å…¥ï¼ŒåŠ å…¥åˆ°payloadä¸­
            if image_base64 is not None:
                payload["input_image"] = image_base64
            if aspect_ratio != "default":
                payload["aspect_ratio"] = aspect_ratio
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                error_tensor = ImageConverter.create_error_image(error_msg, width=512, height=512)
                return error_tensor
            response.raise_for_status()
            result = response.json()

            # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
            image_url = result['result'].get('sample', None)
            if not image_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(image_url)
            response.raise_for_status()
            # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
            img = Image.open(BytesIO(response.content)).convert("RGB")
            return ImageConverter.pil2tensor(img)

        output_tensors = []

        try:
            for i in range(batch_size):
                # å¦‚æœä¸¤æ¬¡è¯·æ±‚ç”¨åŒä¸€ä¸ªseedä¹Ÿè¡Œï¼Œå¯æ”¹ä¸º seed+i å®ç°ä¸åŒseed
                img = call_api(seed + i)
                # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
                # tensor_img = ImageConverter.pil2tensor(img)
                output_tensors.append(img)
                print(f"Flux ç¬¬ {i+1} å¼ å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {prompt}")

            return (torch.cat(output_tensors, dim=0),)  # æ‹¼æ¥ä¸º (æ•°é‡, H, W, 3)

        except Exception as e:
            print(f"Fluxé”™è¯¯: {str(e)}")
            error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
            # è¿”å›æŒ‡å®šæ•°é‡é”™è¯¯å›¾
            error_tensors = [error_tensor for _ in range(batch_size)]
            return (torch.cat(error_tensors, dim=0),)

class FluxMaxNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "seed": ("INT", {"default": -1}),
                "is_translation": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "aspect_ratio": (["default", "1:1", "3:4", "4:3", "9:16", "16:9"], {"default": "default"}),
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
            },
            "optional": {
                "image_input": ("IMAGE", {"default": None}),  # å¯é€‰çš„å›¾åƒè¾“å…¥
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/ImageCreat"

    def generate(self, prompt, seed, batch_size, image_input=None, is_translation=False, aspect_ratio="default"):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        print(f"Flux API URL: {oneapi_url}")  # æ‰“å°API URL

        # å¦‚æœæä¾›äº†å›¾åƒè¾“å…¥ï¼Œå°†å…¶è½¬æ¢ä¸ºbase64
        image_base64 = None
        if image_input is not None:
            try:
                pil_image = ImageConverter.tensor2pil(image_input)
                buffered = BytesIO()
                pil_image.save(buffered, format="JPEG")
                img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
                image_base64 = img_base64
            except Exception as e:
                print(f"å¤„ç†å›¾åƒå¤±è´¥: {e}")
                image_base64 = None

        def call_api(seed_override):
            payload = {
                "model": "flux-context-max",
                "safety_tolerance":6,
                "prompt": prompt,
                "seed": int(seed_override),
                "is_translation": is_translation,  # ä¼ é€’ç¿»è¯‘æ¨¡å¼å‚æ•°
            }
            # å¦‚æœæœ‰å›¾åƒè¾“å…¥ï¼ŒåŠ å…¥åˆ°payloadä¸­
            if image_base64 is not None:
                payload["input_image"] = image_base64
            if aspect_ratio != "default":
                payload["aspect_ratio"] = aspect_ratio
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                error_tensor = ImageConverter.create_error_image(error_msg, width=512, height=512)
                return error_tensor
            response.raise_for_status()
            result = response.json()

            # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
            image_url = result['result'].get('sample', None)
            if not image_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(image_url)
            response.raise_for_status()
            # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
            img = Image.open(BytesIO(response.content)).convert("RGB")
            return ImageConverter.pil2tensor(img)

        output_tensors = []

        try:
            for i in range(batch_size):
                # å¦‚æœä¸¤æ¬¡è¯·æ±‚ç”¨åŒä¸€ä¸ªseedä¹Ÿè¡Œï¼Œå¯æ”¹ä¸º seed+i å®ç°ä¸åŒseed
                img = call_api(seed + i)
                # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
                # tensor_img = ImageConverter.pil2tensor(img)
                output_tensors.append(img)
                print(f"Flux ç¬¬ {i+1} å¼ å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {prompt}")

            return (torch.cat(output_tensors, dim=0),)  # æ‹¼æ¥ä¸º (æ•°é‡, H, W, 3)

        except Exception as e:
            print(f"Fluxé”™è¯¯: {str(e)}")
            error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
            # è¿”å›æŒ‡å®šæ•°é‡é”™è¯¯å›¾
            error_tensors = [error_tensor for _ in range(batch_size)]
            return (torch.cat(error_tensors, dim=0),)



class ReplaceNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "migrate_image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "migrate_mask": ("MASK",),  # è¾“å…¥é®ç½©
                "Product_image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "prompt": ("STRING", {"default": "", "multiline": True}),
                "strong": ("FLOAT", {"default": 0.6}),
                "seed": ("INT", {"default": -1}),  # -1è¡¨ç¤ºéšæœº
            },
            "optional": {
                "Product_mask": ("MASK",),  # å¯é€‰çš„å›¾åƒè¾“å…¥
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("output",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Tools_api"

    def generate(self, Product_image, prompt, migrate_image, seed, strong , Product_mask=None, migrate_mask=None):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        pro_base64 = ImageConverter.merge_image(Product_image, Product_mask)
        mig_base64 = ImageConverter.merge_image(migrate_image, migrate_mask)

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }

        output_tensors = []
        prompt = "This is a collage pictureï¼Œin the left Objects replaces the Objects in the right picture." + prompt

        payload = {
            "model": "Product_migrate_mjAPI",
            "prompt": prompt,
            "strong": strong,
            "seed": seed, 
            "image": pro_base64,
            "imagem": mig_base64
        }

        try:
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=300)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                error_tensor = ImageConverter.create_error_image(error_msg)
                output_tensors.append(error_tensor)
                raise requests.exceptions.HTTPError(f"Request failed with status code {response.status_code}: {error_msg}")
            response.raise_for_status()
            result = response.json()
            result_url = result.get('data')[0].get('fileUrl')

            if not result_url:
                raise ValueError("APIè¿”å›ç©ºå›¾åƒæ•°æ®.")

            responseurl = requests.get(result_url)
            if responseurl.status_code != 200:
                raise ValueError("ä» URL è·å–å›¾ç‰‡å¤±è´¥ã€‚")
            
            img_bytes = responseurl.content
            img = Image.open(BytesIO(img_bytes)).convert("RGB")
            # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
            tensor_img = ImageConverter.pil2tensor(img)
            output_tensors.append(tensor_img)

            print(f"âœ… ReplaceNode è°ƒç”¨æˆåŠŸ")

        except Exception as e:
            print(f"âŒ ReplaceNode é”™è¯¯: {str(e)}")
            # error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
            # output_tensors.append(error_tensor)
        return (torch.cat(output_tensors, dim=0),)  # è¿”å›(batch_size, H, W, 3)


class SeedEdit3:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "prompt": ("STRING", {"default": "", "multiline": True}),
                "cfg_scale": ("FLOAT", {"default": 0.5}),
                "seed": ("INT", {"default": -1}),  # -1è¡¨ç¤ºéšæœº
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # ç”Ÿæˆå¼ æ•°
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("output",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/ImageCreat"

    def generate(self, image, prompt, cfg_scale, seed, batch_size):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        # Convert input tensor to base64
        pil_image = ImageConverter.tensor2pil(image)
        buffered = BytesIO()
        pil_image.save(buffered, format="JPEG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }

        output_tensors = []

        for i in range(batch_size):  # batch_size=2 æ—¶è°ƒç”¨ä¸¤æ¬¡
            payload = {
                "model": "seededit_v3.0",
                "req_key": "seededit_v3.0",
                "prompt": prompt,
                "scale": cfg_scale,
                "seed": seed+i,  # é¿å…å®Œå…¨ä¸€æ ·
                "batch_size": 1,  
                "image_base64": img_base64
            }

            try:
                response = requests.post(oneapi_url, headers=headers, json=payload, timeout=120)
                # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
                if response.status_code != 200:
                    error_msg = ImageConverter.get_status_error_msg(response,1)
                    error_tensor = ImageConverter.create_error_image(error_msg)
                    output_tensors.append(error_tensor)
                    continue
                response.raise_for_status()
                result = response.json()
                img_base64_list = result.get('data', {}).get('binary_data_base64', [])

                if not img_base64_list:
                    raise ValueError("APIè¿”å›ç©ºå›¾åƒæ•°æ®.")

                # æ­£å¸¸æƒ…å†µä¸‹æ¯æ¬¡è¿”å›1å¼ 
                img_bytes = base64.b64decode(img_base64_list[0])
                img = Image.open(BytesIO(img_bytes)).convert("RGB")
                # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
                tensor_img = ImageConverter.pil2tensor(img)
                output_tensors.append(tensor_img)

                print(f"âœ… seededit_v3.0 ç¬¬{i+1}æ¬¡è°ƒç”¨æˆåŠŸ")

            except Exception as e:
                print(f"âŒ seededit_v3.0 é”™è¯¯(ç¬¬{i+1}æ¬¡): {str(e)}")
                error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
                output_tensors.append(error_tensor)

        return (torch.cat(output_tensors, dim=0),)  # è¿”å›(batch_size, H, W, 3)


class KouTuNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "seed": ("INT", {"default": -1}),  # -1è¡¨ç¤ºéšæœº
            },
            "optional": {
                "mask": ("MASK",),  # å¯é€‰çš„å›¾åƒè¾“å…¥
            }

        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("output",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Tools_api"

    def generate(self,  image, seed,  mask=None):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        mig_base64 = ImageConverter.merge_image(image, mask)

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }

        output_tensors = []

        payload = {
            "model": "auto_koutu_1.0",
            "seed": seed, 
            "imagem": mig_base64
        }

        try:
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=300)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                error_tensor = ImageConverter.create_error_image(error_msg)
                output_tensors.append(error_tensor)
                raise requests.exceptions.HTTPError(f"Request failed with status code {response.status_code}: {error_msg}")
            response.raise_for_status()
            result = response.json()
            result_url = result.get('data')[0].get('fileUrl')

            if not result_url:
                raise ValueError("APIè¿”å›ç©ºå›¾åƒæ•°æ®.")

            responseurl = requests.get(result_url)
            if responseurl.status_code != 200:
                raise ValueError("ä» URL è·å–å›¾ç‰‡å¤±è´¥ã€‚")
            
            img_bytes = responseurl.content
            img = Image.open(BytesIO(img_bytes)).convert("RGBA")
            # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
            tensor_img = ImageConverter.pil2tensor(img)
            output_tensors.append(tensor_img)

            print(f"âœ… KouTuNode è°ƒç”¨æˆåŠŸ")

        except Exception as e:
            print(f"âŒ KouTuNode é”™è¯¯: {str(e)}")
        return (torch.cat(output_tensors, dim=0),)  # è¿”å›(batch_size, H, W, 3)

# viduæ–‡ç”Ÿè§†é¢‘
class ViduT2VNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "", "multiline": True}),
                "duration": ("INT", {"default": 5, "min": 1, "max": 8}),
                "resolution": ([ "720p", "1080p"], {"default": "1080p"}),
                "movement_amplitude": (["auto", "small", "medium", "large"], {"default": "auto"}),
                "Size": (["1:1", "9:16", "16:9"], {"default": "16:9"}),
                "bgm": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("VIDEO",)  # è¿”å›VIDEOç±»å‹
    RETURN_NAMES = ("video",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/VideoCreat"

    def generate(self, prompt, seed, duration=5, resolution="1080p", Size="16:9", movement_amplitude="auto", bgm=False):
        # è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        def call_api(seed_override):
            payload = {
                "model": "vidut2vNode",
                "modelr": "viduq2",
                "prompt": prompt,
                "seed": int(seed_override),
                "resolution": resolution,
                "aspect_ratio": Size,
                "duration": duration,
                "movement_amplitude": movement_amplitude,
                "bgm": bgm,
            }

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=400)

            response.raise_for_status()

            result = response.json()
            print(result)

            video_url = result.get('creations', [])[0].get('url', '')
            if not video_url:
                raise ValueError("Empty video data from API.")
            return video_url

        video_url = call_api(seed)
        print(video_url)
        # ä¸‹è½½è§†é¢‘å¹¶æå–å¸§
        video_path = ImageConverter.download_video(video_url)
        # ä½¿ç”¨ VideoFromFile å°è£…è§†é¢‘

        return (VideoFromFile(video_path),)

# vidué¦–å°¾å¸§è§†é¢‘
class ViduI2VNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "first_image": ("IMAGE",),  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
                "prompt": ("STRING", {"default": "", "multiline": True}),
                "duration": ("INT", {"default": 5, "min": 2, "max": 8}),
                "resolution": (["720p", "1080p"], {"default": "1080p"}),
                "movement_amplitude": (["auto", "small", "medium", "large"], {"default": "auto"}),
                "bgm": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "seed": ("INT", {"default": -1}),
            },
            "optional": {
                "last_image": ("IMAGE",),  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
            }
        }

    RETURN_TYPES = ("VIDEO",)  # è¿”å›VIDEOç±»å‹
    RETURN_NAMES = ("video",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/VideoCreat"

    def generate(self, prompt,  seed,duration=5, resolution="1080p", Size="16:9", movement_amplitude="auto", bgm=False, first_image=None, last_image=None):
        # è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()
        images = []
        first_image_base64 = ImageConverter.tensor_to_base64(first_image)
        images.append(first_image_base64)
        if last_image is not None:
            last_image_base64 = ImageConverter.tensor_to_base64(last_image)
            images.append(last_image_base64)
        
        def call_api(seed_override):
            payload = {
                "model": "vidui2vNode",
                "modelr": "viduq2-turbo",
                "prompt": prompt,
                "seed": int(seed_override),
                "resolution": resolution,
                "duration": duration,
                "movement_amplitude": movement_amplitude,
                "bgm": bgm,
                "images": images,
            }

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=400)

            response.raise_for_status()

            result = response.json()
            print(result)

            video_url =  result.get('creations', [])[0].get('url', '')
            if not video_url:
                raise ValueError("Empty video data from API.")
            return video_url

        video_url = call_api(seed)
        print(video_url)
        # ä¸‹è½½è§†é¢‘å¹¶æå–å¸§
        video_path = ImageConverter.download_video(video_url)
        # ä½¿ç”¨ VideoFromFile å°è£…è§†é¢‘

        return (VideoFromFile(video_path),)


# seedanceæ–‡ç”Ÿè§†é¢‘
class DreaminaT2VNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "", "multiline": True}),
                "resolution": (["480P", "720P", "1080p"], {"default": "1080p"}),
                "Size": (["1:1", "3:4", "4:3", "9:16", "16:9", "21:9"], {"default": "16:9"}),
                "duration": ("INT", {"default": 10, "min": 3, "max": 12}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
                "camerafixed": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("VIDEO",)  # è¿”å›VIDEOç±»å‹
    RETURN_NAMES = ("video",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/VideoCreat"

    def generate(self, prompt, seed,  resolution="1080p", Size="16:9", duration=10, camerafixed=False):
        # è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        def call_api(seed_override):
            payload = {
                "model": "Dreaminat2vNode",
                "prompt": prompt,
                "seed": int(seed_override),
                "resolution": resolution,
                "Size": Size,
                "duration": duration,
                "camerafixed": camerafixed,
            }

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=240)

            response.raise_for_status()

            result = response.json()
            print(result)

            video_url = result.get("content").get("video_url")
            if not video_url:
                raise ValueError("Empty video data from API.")
            return video_url

        video_url = call_api(seed)
        print(video_url)
        # ä¸‹è½½è§†é¢‘å¹¶æå–å¸§
        video_path = ImageConverter.download_video(video_url)
        # ä½¿ç”¨ VideoFromFile å°è£…è§†é¢‘

        return (VideoFromFile(video_path),)



# seedanceå›¾ç”Ÿè§†é¢‘ + seedanceé¦–å°¾å¸§è§†é¢‘
class DreaminaI2VNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "first_image": ("IMAGE",),  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
                "prompt": ("STRING", {"default": "", "multiline": True}),
                "resolution": (["480P", "720P", "1080p"], {"default": "1080p"}),
                "Size": (["1:1", "3:4", "4:3", "9:16", "16:9", "21:9"], {"default": "16:9"}),
                "duration": ("INT", {"default": 10, "min": 3, "max": 12}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
                "camerafixed": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "seed": ("INT", {"default": -1}),
            },
            "optional": {
                "last_image": ("IMAGE",),  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
            }
        }

    RETURN_TYPES = ("VIDEO",)  # è¿”å›VIDEOç±»å‹
    RETURN_NAMES = ("video",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/VideoCreat"

    def generate(self, prompt, seed, first_image, resolution="1080p", Size="16:9", duration=10, camerafixed=False, last_image=None):
        # è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()
        first_image_base64 = ImageConverter.tensor_to_base64(first_image)
        def call_api(seed_override):
            payload = {
                "model": "DreaminaI2VNode",
                "prompt": prompt,
                "resolution": resolution,
                "Size": Size,
                "duration": duration,
                "camerafixed": camerafixed,
                "seed": int(seed_override),
                "first_image_base64": first_image_base64,
            }
            if last_image is not None:
                last_image_base64 = ImageConverter.tensor_to_base64(last_image)
                payload["last_image_base64"] = last_image_base64
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=240)

            response.raise_for_status()

            result = response.json()
            print(result)

            video_url = result.get("content").get("video_url")
            if not video_url:
                raise ValueError("Empty video data from API.")
            return video_url

        # è°ƒç”¨API
        video_url = call_api(seed)
        print(video_url)
        # ä¸‹è½½è§†é¢‘å¹¶æå–å¸§
        video_path = ImageConverter.download_video(video_url)
        # ä½¿ç”¨ VideoFromFile å°è£…è§†é¢‘

        return (VideoFromFile(video_path),)


class QwenImageNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "size": (["1328*1328", "1664*928", "1472*1140", "1140*1472", "928*1664"], {"default": "1328*1328"}),
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
                "prompt_extend": ("BOOLEAN", {"default": True}),  # æ˜¯å¦å¼€å¯promptæ™ºèƒ½æ”¹å†™
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/ImageCreat"

    def generate(self, prompt, size, batch_size,seed,prompt_extend):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        def call_api():
            payload = {
                "model": "qwen-image",
                "modelr": "qwen-image",
                "prompt": prompt,
                "prompt_extend": prompt_extend,
                "size": size,
            }
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=60)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response,1)
                error_tensor = ImageConverter.create_error_image(error_msg, 512, 512)
                return error_tensor

            response.raise_for_status()
            result = response.json()
            # å¤„ç†URLåˆ—è¡¨è·å–å›¾ç‰‡æ•°æ®
            img_bytes_list = []
            url = result.get('output').get('results', [])[0].get('url', None)
            response = requests.get(url)
            response.raise_for_status()
            img_bytes_list.append(response.content)
            
            # è½¬æ¢ä¸ºBase64æ ¼å¼
            img_base64_list = [base64.b64encode(img_bytes).decode('utf-8') for img_bytes in img_bytes_list]
            img_data = img_base64_list[0]  # å–ç¬¬ä¸€å¼ å›¾ç‰‡
            img_bytes = base64.b64decode(img_data)
            img = Image.open(BytesIO(img_bytes)).convert("RGB")
            return ImageConverter.pil2tensor(img)

        output_tensors = []

        try:
            for i in range(batch_size):
                img_tensor = call_api()
                if isinstance(img_tensor, torch.Tensor):
                    # åˆ¤æ–­æ˜¯å¦ä¸ºé”™è¯¯å›¾åƒ tensor
                    if img_tensor.shape[1] == 512 and img_tensor.shape[2] == 512 and img_tensor[0, 0, 0, 0] == 1:
                        return (img_tensor,)
                output_tensors.append(img_tensor)
                print(f"QwenImageNode ç¬¬ {i+1} å¼ å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {prompt} ()")

            return (torch.cat(output_tensors, dim=0),)  # æ‹¼æ¥ä¸º (æ•°é‡, H, W, 3)

        except Exception as e:
            print(f"QwenImageNode é”™è¯¯: {str(e)}")
            error_tensor = ImageConverter.create_error_image(str(e))
            error_tensors = [error_tensor for _ in range(batch_size)]
            return (torch.cat(error_tensors, dim=0),)


class QwenImageEditNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "", "multiline": True}),
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/ImageCreat"

    def generate(self, prompt,image, batch_size,seed):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        image_base64 = ImageConverter.tensor_to_base64(image)

        def call_api():
            payload = {
                "model": "qwen-image-edit",
                "prompt": prompt,
                "image": image_base64,
            }
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=60)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response,1)
                error_tensor = ImageConverter.create_error_image(error_msg, 512, 512)
                return error_tensor

            response.raise_for_status()
            result = response.json()
            # å¤„ç†URLåˆ—è¡¨è·å–å›¾ç‰‡æ•°æ®
            img_bytes_list = []
            url = result.get('output', {}).get('choices', [{}])[0].get('message', {}).get('content', [{}])[0].get('image', None)
            response = requests.get(url)
            response.raise_for_status()
            img_bytes_list.append(response.content)
            
            # è½¬æ¢ä¸ºBase64æ ¼å¼
            img_base64_list = [base64.b64encode(img_bytes).decode('utf-8') for img_bytes in img_bytes_list]
            img_data = img_base64_list[0]  # å–ç¬¬ä¸€å¼ å›¾ç‰‡
            img_bytes = base64.b64decode(img_data)
            img = Image.open(BytesIO(img_bytes)).convert("RGB")
            return ImageConverter.pil2tensor(img)

        output_tensors = []

        try:
            for i in range(batch_size):
                img_tensor = call_api()
                if isinstance(img_tensor, torch.Tensor):
                    # åˆ¤æ–­æ˜¯å¦ä¸ºé”™è¯¯å›¾åƒ tensor
                    if img_tensor.shape[1] == 512 and img_tensor.shape[2] == 512 and img_tensor[0, 0, 0, 0] == 1:
                        return (img_tensor,)
                output_tensors.append(img_tensor)
                print(f"QwenImageNode ç¬¬ {i+1} å¼ å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {prompt} ()")

            return (torch.cat(output_tensors, dim=0),)  # æ‹¼æ¥ä¸º (æ•°é‡, H, W, 3)

        except Exception as e:
            print(f"QwenImageNode é”™è¯¯: {str(e)}")
            error_tensor = ImageConverter.create_error_image(str(e))
            error_tensors = [error_tensor for _ in range(batch_size)]
            return (torch.cat(error_tensors, dim=0),)


class GetDressing:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "extend_prompt": ([ "é»˜è®¤","å…¨èº«", "ä¸Šèº«", "ä¸‹èº«","å¤–å¥—"], {"default": "é»˜è®¤"}),
                "size": ([ "1:1", "3:4", "4:3"], {"default": "1:1"}),
                "seed": ("INT", {"default": -1}),  # -1è¡¨ç¤ºéšæœº
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("output",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Product&tool"

    def generate(self,  image, seed,  extend_prompt,size="1:1"):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        mig_base64 = ImageConverter.tensor_to_base64(image)

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }

        output_tensors = []
        if seed == -1:
            seed = random.randint(0, 999999)

        payload = {
            "model": "mojie_get_dressing",
            "seed": seed, 
            "aspect_ratio": size,
            "input_image": mig_base64,
            "watermark": False,
            "extend_prompt": extend_prompt
        }

        try:
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=300)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                error_tensor = ImageConverter.create_error_image(error_msg)
                output_tensors.append(error_tensor)
                raise requests.exceptions.HTTPError(f"Request failed with status code {response.status_code}: {error_msg}")
            response.raise_for_status()
            result = response.json()
            result_url = result.get("res_url")

            if not result_url:
                raise ValueError("APIè¿”å›ç©ºå›¾åƒæ•°æ®.")

            responseurl = requests.get(result_url)
            if responseurl.status_code != 200:
                raise ValueError("ä» URL è·å–å›¾ç‰‡å¤±è´¥ã€‚")
            
            img_bytes = responseurl.content
            img = Image.open(BytesIO(img_bytes)).convert("RGBA")
            # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
            tensor_img = ImageConverter.pil2tensor(img)
            output_tensors.append(tensor_img)

            print(f"âœ… GetDressing è°ƒç”¨æˆåŠŸ")

        except Exception as e:
            print(f"âŒ GetDressing é”™è¯¯: {str(e)}")
        return (torch.cat(output_tensors, dim=0),)  # è¿”å›(batch_size, H, W, 3)

class ViduNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "aspect_ratio": ([ "16:9", "9:16", "1:1"], {"default": "16:9"}),
                "duration": ("INT", {"default": 5, "min": 1, "max": 8}),
                "resolution": (["720p", "1080p"], {"default": "1080p"}),
                "movement_amplitude": (["auto", "small", "medium", "large"], {"default": "auto"}),
                "seed": ("INT", {"default": -1}),
                "images": ("IMAGE", {"default": []})  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
            }
        }

    RETURN_TYPES = ("VIDEO",)  # è¿”å›VIDEOç±»å‹
    RETURN_NAMES = ("video",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/VideoCreat"

    def generate(self, prompt, seed, aspect_ratio="16:9", duration=5, resolution="1080p", movement_amplitude="auto", images=[]):
        # è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        def call_api(seed_override, binary_data_base64):
            payload = {
                "model": "vidu_video",
                "modelr": "viduq2",
                "aspect_ratio": aspect_ratio,
                "prompt": prompt,
                "duration": duration,
                "seed": 0,
                "images": binary_data_base64,  # æ·»åŠ Base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
                "resolution": resolution,
                "movement_amplitude": movement_amplitude,
            }
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=240)

            response.raise_for_status()

            result = response.json()
            print(result)

            video_url = result.get('creations', [])[0].get('url', '')
            if not video_url:
                raise ValueError("Empty video data from API.")
            return video_url

        # å°†å›¾åƒè½¬æ¢ä¸ºBase64ç¼–ç 
        binary_data_base64 = ImageConverter.convert_images_to_base64(images)

        # è°ƒç”¨API
        video_url = call_api(0, binary_data_base64)
        print(video_url)
        # ä¸‹è½½è§†é¢‘å¹¶æå–å¸§
        video_path = ImageConverter.download_video(video_url)
        # ä½¿ç”¨ VideoFromFile å°è£…è§†é¢‘

        return (VideoFromFile(video_path),)


class ReplaceClothesNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "cloths_image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "model_image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "seed": ("INT", {"default": -1}),  # -1è¡¨ç¤ºéšæœº
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("output",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Product&tool"

    def generate(self, cloths_image, model_image, seed):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        # è·å–model_imageçš„å°ºå¯¸å¹¶è®¡ç®—å®½é«˜æ¯”
        height, width = model_image.shape[1], model_image.shape[2]  # è·å–å›¾åƒçš„é«˜åº¦å’Œå®½åº¦
        image_ratio = width / height  # è®¡ç®—å›¾åƒçš„å®½é«˜æ¯”
        print(f"æ¨¡ç‰¹å›¾ç‰‡å®½é«˜æ¯”ä¾‹: {image_ratio}")
        # é¢„å®šä¹‰çš„å®½é«˜æ¯”åˆ—è¡¨åŠå…¶å¯¹åº”çš„æ¯”å€¼
        aspect_ratios = {
            "21:9": 21/9,
            "16:9": 16/9,
            "4:3": 4/3,
            "3:2": 3/2,
            "1:1": 1/1,
            "5:4": 5/4,
            "4:5": 4/5,
            "3:4": 3/4,
            "2:3": 2/3,
            "9:16": 9/16
        }
        
        # æ‰¾å‡ºæœ€æ¥è¿‘çš„å®½é«˜æ¯”
        closest_ratio = min(aspect_ratios, key=lambda x: abs(aspect_ratios[x] - image_ratio))
        print(f"æœ€æ¥è¿‘çš„å®½é«˜æ¯”: {closest_ratio}")


        imput_image = []
        imput_image.append(ImageConverter.tensor_to_base64(model_image))
        imput_image.append(ImageConverter.tensor_to_base64(cloths_image))

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }

        output_tensors = []

        payload = {
            "model": "dressV2ing_diffusion",
            "Custom_prompt": False,
            "seed": seed, 
            "aspect_ratio": closest_ratio,
            "input_image": imput_image,
        }

        try:
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=300)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                error_tensor = ImageConverter.create_error_image(error_msg)
                output_tensors.append(error_tensor)
                raise requests.exceptions.HTTPError(f"Request failed with status code {response.status_code}: {error_msg}")
            response.raise_for_status()
            result = response.json()
            result_url = result.get("res_url")

            if not result_url:
                raise ValueError("APIè¿”å›ç©ºå›¾åƒæ•°æ®.")

            responseurl = requests.get(result_url)
            if responseurl.status_code != 200:
                raise ValueError("ä» URL è·å–å›¾ç‰‡å¤±è´¥ã€‚")
            
            img_bytes = responseurl.content
            img = Image.open(BytesIO(img_bytes)).convert("RGB")

            # img = ImageConverter.get_right_part_of_image(img)
            # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
            tensor_img = ImageConverter.pil2tensor(img)
            output_tensors.append(tensor_img)

            print(f"âœ… ReplaceNode è°ƒç”¨æˆåŠŸ")

        except Exception as e:
            print(f"âŒ ReplaceNode é”™è¯¯: {str(e)}")
            # error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
            # output_tensors.append(error_tensor)
        return (torch.cat(output_tensors, dim=0),)  # è¿”å›(batch_size, H, W, 3)


class GeminiEditNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "is_translation": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "Size": (["1:1", "3:4", "4:3", "9:16", "16:9"], {"default": "3:4"}),
                "mount": ("INT", {"default": 1, "min": 1, "max": 4}),  # ç”Ÿæˆå¼ æ•°
                "seed": ("INT", {"default": -1}),
            },
            "optional": {
                "image_input": ("IMAGE", {"default": []}),  # å¯é€‰çš„å›¾åƒè¾“å…¥
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/ImageCreat"

    def generate(self, prompt, seed, image_input=[], is_translation=False, Size="3:4", mount=1):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        def call_api(seed_override):
            payload = {
                "model": "gemini-2.5-flash-image",
                "prompt": prompt,
                "is_translation": is_translation,  # ä¼ é€’ç¿»è¯‘æ¨¡å¼å‚æ•°
                "aspect_ratio": Size,  # ä¼ é€’å°ºå¯¸å‚æ•°
                "mount": mount,  # ç”Ÿæˆå¼ æ•°
                "seed": int(seed_override),
            }
            # å¦‚æœæœ‰å›¾åƒè¾“å…¥ï¼ŒåŠ å…¥åˆ°payloadä¸­
            if len(image_input) > 0:
                binary_data_base64 = ImageConverter.convert_images_to_base64(image_input)
                payload["input_image"] = binary_data_base64

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            print(f"Gemini API å“åº”çŠ¶æ€ç : {response.status_code}")
            if response.status_code != 200:
                raise requests.exceptions.HTTPError(f"Request failed with status code {response.status_code}: {response.text}")
                # error_msg = ImageConverter.get_status_error_msg(response)
                # error_tensor = ImageConverter.create_error_image(error_msg, width=512, height=512)
                # return (torch.cat(error_tensor, dim=0),)
            response.raise_for_status()
            result = response.json()

            # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
            image_url = result.get("res_url")

            if not image_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
            image_urls = image_url.split("|") if image_url else []

            api_tensors = []
            print(image_urls)
            for image_url in image_urls:
                if not image_url:
                    continue
                try:
                    # ä¸‹è½½å›¾ç‰‡
                    response = requests.get(image_url)
                    response.raise_for_status()
                    # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
                    img = Image.open(BytesIO(response.content)).convert("RGB")
                    api_tensors.append(ImageConverter.pil2tensor(img))
                except Exception as e:
                    print(f"ä¸‹è½½å›¾ç‰‡ {image_url} å¤±è´¥: {str(e)}")
                    error_tensor = ImageConverter.create_error_image("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                    api_tensors.append(error_tensor)

            if not api_tensors:
                error_tensor = ImageConverter.create_error_image("æœªè·å–åˆ°æœ‰æ•ˆå›¾ç‰‡ URL")
                api_tensors.append(error_tensor)

            return (torch.cat(api_tensors, dim=0),)

        try:
            return call_api(seed + 666)

        except Exception as e:
            print(f"Gemini: {str(e)}")
            error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
            # è¿”å›æŒ‡å®šæ•°é‡é”™è¯¯å›¾
            error_tensors = [error_tensor for _ in range(1)]
            return (torch.cat(error_tensors, dim=0),)


class DoubaoSeedreamNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "seed": ("INT", {"default": -1}),
                "custom_size": ("BOOLEAN", {"default": False}),  # è‡ªå®šä¹‰å°ºå¯¸å¼€å…³
                "size": (["2048x2048", "2304x1728", "1728x2304", "2560x1440", "1440x2560", "2496x1664", "1664x2496", "3024x1296"], {"default": "2048x2048"}),
                "width": ("INT", {"default": 1024, "min": 1024, "max": 4096}),  # ç”Ÿæˆå¼ æ•°
                "height": ("INT", {"default": 1024, "min": 1024, "max": 4096}),  # ç”Ÿæˆå¼ æ•°
                "max_SetImage": (["off", 'auto'], {"default": "off"}),  
            },
            "optional": {
                "image_input": ("IMAGE", {"default": []}),  # å¯é€‰çš„å›¾åƒè¾“å…¥
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/ImageCreat"

    def generate(self, prompt, seed, image_input=None,width=1024,height=1024,custom_size=True,size="1024x1024",max_SetImage="off"):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        if custom_size == False:
            resl_size = size
        else:
            resl_size = f"{width}x{height}"

        count = 1 if max_SetImage == 'off' else 15

        payload = {
            "model": "doubao-seedream-4.5",
            "prompt": prompt,
            "size": resl_size, 
            "seed": int(seed+6),
            "watermark": False,
            "max_SetImage": count,
            "pro": True,
        }
        # å¦‚æœæœ‰å›¾åƒè¾“å…¥ï¼ŒåŠ å…¥åˆ°payloadä¸­
        if image_input is not None:
            binary_data_base64 = ImageConverter.convert_images_to_base64(image_input)
            payload["input_image"] = binary_data_base64

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }
        response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
        # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
        if response.status_code != 200:
            error_msg = ImageConverter.get_status_error_msg(response)
            print("é”™è¯¯ä¿¡æ¯",error_msg)
            output_tensors = []
            error_tensor = ImageConverter.create_error_image(error_msg)
            output_tensors.append(error_tensor)
            return (torch.cat(output_tensors, dim=0),)
        response.raise_for_status()
        result = response.json()

        # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
        res_url = result.get("res_url", "")
        if not res_url:
            raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
        image_urls = res_url.split("|") if res_url else []

        api_tensors = []
        print(image_urls)
        for image_url in image_urls:
            if not image_url:
                continue
            try:
                # ä¸‹è½½å›¾ç‰‡
                response = requests.get(image_url)
                response.raise_for_status()
                # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
                img = Image.open(BytesIO(response.content)).convert("RGB")
                api_tensors.append(ImageConverter.pil2tensor(img))
            except Exception as e:
                print(f"ä¸‹è½½å›¾ç‰‡ {image_url} å¤±è´¥: {str(e)}")
                error_tensor = ImageConverter.create_error_image("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                api_tensors.append(error_tensor)

        if not api_tensors:
            error_tensor = ImageConverter.create_error_image("æœªè·å–åˆ°æœ‰æ•ˆå›¾ç‰‡ URL")
            api_tensors.append(error_tensor)

        return (torch.cat(api_tensors, dim=0),)


class ModelGenNode:
    @classmethod
    def INPUT_TYPES(cls):
        # å‘é€è¯·æ±‚
        url = "https://qihuaimage.com/api/mjapi/styles/"
        response = requests.get(url)
        response.raise_for_status()
        result = response.json()
        styles = result.get("data", [])
        style_prompt = [item["name"] for item in styles]
        return {
            "required": {
                "cloths_image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "race_class": (["äºšè£”", "é»‘äºº", "ç™½äºº"], {"default": "äºšè£”"}),
                "gender_class": (["man", "woman", "little boy","little girl"], {"default": "woman"}),
                "style_prompt": (style_prompt, {"default": "é€šç”¨-INSè‡ªæ‹"}),
                "seed": ("INT", {"default": -1}),
                "Size": (["1:1", "3:4", "9:16"], {"default": "3:4"}),
            },
            "optional": {
                "face_image": ("IMAGE", {"default": None}),  # å¯é€‰çš„å›¾åƒè¾“å…¥
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Product&tool"

    def generate(self , seed, face_image=None, cloths_image=None,race_class="Asia",gender_class="woman",style_prompt="INSè‡ªæ‹é£",Size="3:4"):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        cloths_image_base64 = ImageConverter.tensor_to_base64(cloths_image)

        races = {
            "äºšè£”": "Asia",
            "é»‘äºº": "black",
            "ç™½äºº": "Ukraine"
        }
        race_class = races.get(race_class, "Asia")

        is_face = True if face_image is not None else False

        def call_api(seed_override):
            payload = {
                "model": "mojie-output-moter",
                "gender_class": gender_class,
                "race_class": race_class,
                "seed": int(seed_override),
                "is_face": is_face,
                "style_prompt": style_prompt,
                "aspect_ratio": Size,  # ä¼ é€’å°ºå¯¸å‚æ•°
                "cloths_image": cloths_image_base64
            }
            if face_image is not None:
                face_image_base64 = ImageConverter.tensor_to_base64(face_image)
                payload["face_image"] = face_image_base64


            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                error_tensor = ImageConverter.create_error_image(error_msg, width=512, height=512)
                return error_tensor
            response.raise_for_status()
            result = response.json()

            # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
            image_url = result.get("res_url")

            if not image_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(image_url)
            response.raise_for_status()
            # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
            img = Image.open(BytesIO(response.content)).convert("RGB")
            # è°ƒç”¨å°è£…çš„å‡½æ•°è£å‰ªç™½è‰²è¾¹æ¡†
            # img = ImageConverter.crop_white_borders(img)
            return ImageConverter.pil2tensor(img)

        output_tensors = []

        try:
            for i in range(1):
                # å¦‚æœä¸¤æ¬¡è¯·æ±‚ç”¨åŒä¸€ä¸ªseedä¹Ÿè¡Œï¼Œå¯æ”¹ä¸º seed+i å®ç°ä¸åŒseed
                img = call_api(seed + i)
                # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
                # tensor_img = ImageConverter.pil2tensor(img)
                output_tensors.append(img)
                print(f"MojieClothesAPI ç¬¬ {i+1} å¼ å›¾ç‰‡ç”ŸæˆæˆåŠŸ")

            return (torch.cat(output_tensors, dim=0),)  # æ‹¼æ¥ä¸º (æ•°é‡, H, W, 3)

        except Exception as e:
            print(f"MojieClothesAPI: {str(e)}")
            error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
            # è¿”å›æŒ‡å®šæ•°é‡é”™è¯¯å›¾
            error_tensors = [error_tensor for _ in range(1)]
            return (torch.cat(error_tensors, dim=0),)


class MoterPoseNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_input": ("IMAGE", {"default": None}),  # å¯é€‰çš„å›¾åƒè¾“å…¥
                "extent_prompt": ("BOOLEAN", {"default": True}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "out_batch": ("INT", {"default": 1, "min": 1, "max": 4}),  # ç”Ÿæˆå¼ æ•°
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Product&tool"

    def generate(self,  seed, image_input=None, extent_prompt=False,out_batch=1):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        def call_api(seed_override):
            payload = {
                "model": "moter-pose-change",
                "extent_prompt": extent_prompt,  # ä¼ é€’ç¿»è¯‘æ¨¡å¼å‚æ•°
                "seed": int(seed_override),
                "watermark": False,
                "mount": out_batch,
                "input_image": ImageConverter.tensor_to_base64(image_input)
            }

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                raise requests.exceptions.HTTPError(f"Request failed with status code {response.status_code}: {response.text}")
                # error_msg = ImageConverter.get_status_error_msg(response)
                # error_tensor = ImageConverter.create_error_image(error_msg, width=512, height=512)
                # return error_tensor
            response.raise_for_status()
            result = response.json()

            # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
            image_url = result.get("res_url")

            if not image_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
            image_urls = image_url.split("|") if image_url else []

            api_tensors = []
            print(image_urls)
            for image_url in image_urls:
                if not image_url:
                    continue
                try:
                    # ä¸‹è½½å›¾ç‰‡
                    response = requests.get(image_url)
                    response.raise_for_status()
                    # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
                    img = Image.open(BytesIO(response.content)).convert("RGB")
                    api_tensors.append(ImageConverter.pil2tensor(img))
                except Exception as e:
                    print(f"ä¸‹è½½å›¾ç‰‡ {image_url} å¤±è´¥: {str(e)}")
                    error_tensor = ImageConverter.create_error_image("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                    api_tensors.append(error_tensor)

            if not api_tensors:
                error_tensor = ImageConverter.create_error_image("æœªè·å–åˆ°æœ‰æ•ˆå›¾ç‰‡ URL")
                api_tensors.append(error_tensor)

            return (torch.cat(api_tensors, dim=0),)

        try:
            return call_api(seed + 666)
        except Exception as e:
            print(f": {str(e)}")
            error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
            # è¿”å›æŒ‡å®šæ•°é‡é”™è¯¯å›¾
            error_tensors = [error_tensor for _ in range(1)]
            return (torch.cat(error_tensors, dim=0),)


class ImageTranslateNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_input": ("IMAGE", {"default": []}),  # å¯é€‰çš„å›¾åƒè¾“å…¥
                "modelid": (["default", "erase" ], {"default": "default"}),
                "SourceLang": (["è‡ªåŠ¨","é˜¿æ‹‰ä¼¯è¯­", "æ³•è¯­", "è‹±è¯­",  "åŠ æ³°ç½—å°¼äºšè¯­", "è‘¡è„ç‰™è¯­", "è¥¿ç­ç‰™è¯­", "è·å…°è¯­", "å¾·è¯­", "æ–¯æ´›æ–‡å°¼äºšè¯­", "é˜¿å¡æ‹œç–†è¯­", "å­ŸåŠ æ‹‰è¯­", "ä¿„è¯­", "æŒªå¨è¯­", "é©¬æ¥è¯­", "ä¸­æ–‡", "ä¸­æ–‡ (ç¹ä½“)", "æ·å…‹è¯­", "æ–¯æ´›ä¼å…‹è¯­", "æ³¢å…°è¯­", "åŒˆç‰™åˆ©è¯­", "è¶Šå—è¯­", "ä¸¹éº¦è¯­", "èŠ¬å…°è¯­", "ç‘å…¸è¯­", "å°å°¼è¯­", "å¸Œä¼¯æ¥è¯­", "æ„å¤§åˆ©è¯­", "æ—¥è¯­", "éŸ©è¯­", "æ³°ç±³å°”è¯­", "æ³°è¯­", "åœŸè€³å…¶è¯­"], {"default": "è‡ªåŠ¨"}),
                "TargetLang": (["è‹±è¯­","ä¸­æ–‡", "ä¸­æ–‡ (ç¹ä½“)",   "æ—¥è¯­", "éŸ©è¯­", "é˜¿æ‹‰ä¼¯è¯­", "è‘¡è„ç‰™è¯­", "æ³•è¯­", "å¾·è¯­", "è¥¿ç­ç‰™è¯­", "å°å°¼è¯­", "æ„å¤§åˆ©è¯­", "é©¬æ¥è¯­", "ä¿„è¯­", "æ³°è¯­", "è¶Šå—è¯­"], {"default": "è‹±è¯­"}),
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Tools_api"

    def generate(self, seed, image_input=[], modelid="default", SourceLang="auto", TargetLang="auto"):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()
        
        def call(img):
            binary_data_base64 = ImageConverter.tensor_to_base64(img)

            payload = {
                "model": "image_translate",
                "seed": int(seed+6),
                "input_image": binary_data_base64,
                "modelid": modelid,
                "SourceLang": ImageConverter.get_lang(SourceLang),
                "TargetLang": ImageConverter.get_lang(TargetLang),
            }

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                print("é”™è¯¯ä¿¡æ¯",error_msg)
                output_tensors = []
                error_tensor = ImageConverter.create_error_image(error_msg)
                output_tensors.append(error_tensor)
                return (torch.cat(output_tensors, dim=0),)
            response.raise_for_status()
            result = response.json()

            # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
            res_url = result.get("res_url", "")
            if not res_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
            return res_url

        api_tensors = []
        for img in image_input:
            try:
                # å®½é«˜
                width, height = img.shape[2], img.shape[1]
                print(f"å›¾ç‰‡å®½é«˜: {width}x{height}")

                res_url = call(img)
                response = requests.get(res_url)
                response.raise_for_status()
                # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
                img = Image.open(BytesIO(response.content)).convert("RGB")
                api_tensors.append(ImageConverter.pil2tensor(img))
            except Exception as e:
                print(f"ä¸‹è½½å›¾ç‰‡ {res_url} å¤±è´¥: {str(e)}")
                error_tensor = ImageConverter.create_error_image("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                api_tensors.append(error_tensor)

        if not api_tensors:
            error_tensor = ImageConverter.create_error_image("æœªè·å–åˆ°æœ‰æ•ˆå›¾ç‰‡ URL")
            api_tensors.append(error_tensor)

        return (torch.cat(api_tensors, dim=0),)

class ImageUpscaleNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image_input": ("IMAGE", {"default": []}),  # å¯é€‰çš„å›¾åƒè¾“å…¥
                "seed": ("INT", {"default": -1}),
                "multiple": (["x2", "x4", "x6"], {"default": "x2"}),
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Tools_api"

    def generate(self, seed, image_input=[], multiple="x2"):

            
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        multiple_map = {
            "x2": 2,
            "x4": 4,
            "x6": 6,
            "x8": 8,
        }
        multiple = multiple_map[multiple]

        def call(img):
            binary_data_base64 = ImageConverter.tensor_to_base64(img)

            payload = {
                "model": "image_upscale",
                "seed": int(seed+6),
                "input_image": binary_data_base64,
                "multiple": multiple,
            }

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                print("é”™è¯¯ä¿¡æ¯",error_msg)
                output_tensors = []
                error_tensor = ImageConverter.create_error_image(error_msg)
                output_tensors.append(error_tensor)
                return (torch.cat(output_tensors, dim=0),)
            response.raise_for_status()
            result = response.json()

            # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
            res_url = result.get("res_url", "")
            if not res_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
            return res_url

        api_tensors = []
        for img in image_input:
            try:

                # è·å–å›¾ç‰‡å°ºå¯¸
                # print("å¤„ç†å›¾ç‰‡...",len(img.shape))
                height, width = img.shape[0], img.shape[1]
                print(f"å›¾ç‰‡å®½é«˜: {width}x{height}")

                # print("====== å›¾åƒè¾“å…¥è°ƒè¯• ======")
                # print("ç±»å‹:", type(img))

                # if isinstance(img, torch.Tensor):
                #     print("å½¢çŠ¶:", img.shape)
                #     print("æ•°æ®ç±»å‹:", img.dtype)
                #     print("å€¼èŒƒå›´:", (float(img.min()), float(img.max())))
                #     print("å‰10ä¸ªåƒç´ å€¼:", img.flatten()[:10])
                # elif isinstance(img, list) or isinstance(img, tuple):
                #     print("åˆ—è¡¨é•¿åº¦:", len(img))
                #     if len(img) > 0 and isinstance(img[0], torch.Tensor):
                #         print("ç¬¬ä¸€ä¸ªå…ƒç´ å½¢çŠ¶:", img[0].shape)
                # else:
                #     print("æœªçŸ¥ç»“æ„:", img)
                # print("=========================")
                
                # æ£€æŸ¥å›¾ç‰‡å°ºå¯¸æ˜¯å¦æ»¡è¶³è¦æ±‚
                min_size = 256
                max_size = 2048
                
                # è°ƒæ•´å›¾ç‰‡å°ºå¯¸ä»¥æ»¡è¶³è¦æ±‚
                if width < min_size or height < min_size or width > max_size or height > max_size:
                    # è®¡ç®—ç¼©æ”¾å› å­
                    scale_factor = 1.0
                    
                    # å¤„ç†è¿‡å°çš„æƒ…å†µ
                    if width < min_size or height < min_size:
                        scale_factor = max(min_size / width, min_size / height)
                    
                    # å¤„ç†è¿‡å¤§çš„æƒ…å†µ
                    new_width = int(width * scale_factor)
                    new_height = int(height * scale_factor)
                    if new_width > max_size or new_height > max_size:
                        scale_factor = min(max_size / width, max_size / height)
                    
                    # è®¡ç®—æ–°çš„å°ºå¯¸
                    new_width = int(width * scale_factor)
                    new_height = int(height * scale_factor)
                    print(f"è°ƒæ•´å›¾ç‰‡å°ºå¯¸è‡³: {new_width}x{new_height}")
                    
                    # è½¬æ¢å¹¶è°ƒæ•´å°ºå¯¸
                    pil_img = ImageConverter.tensor2pil(img)
                    pil_img = pil_img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                    img = ImageConverter.pil2tensor(pil_img)
                else:
                    new_width = width
                    new_height = height

                # å¦‚æœå®½é«˜*multipleå¤§äº10240ï¼Œå°±ç›´æ¥åŸå›¾è¾“å‡º
                if new_width * multiple > 10240 or new_height * multiple > 10240:
                    print(f"å›¾ç‰‡å°ºå¯¸ {new_width}x{new_height} è¶…è¿‡æœ€å¤§é™åˆ¶ 10240x10240,ç›´æ¥è¾“å‡ºåŸå›¾")
                    api_tensors.append(img)
                    continue


                res_url = call(img)
                response = requests.get(res_url)
                response.raise_for_status()
                # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
                img = Image.open(BytesIO(response.content)).convert("RGB")
                api_tensors.append(ImageConverter.pil2tensor(img))
            except Exception as e:
                error_tensor = ImageConverter.create_error_image("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                api_tensors.append(error_tensor)

        if not api_tensors:
            error_tensor = ImageConverter.create_error_image("æœªè·å–åˆ°æœ‰æ•ˆå›¾ç‰‡ URL")
            api_tensors.append(error_tensor)

        return (torch.cat(api_tensors, dim=0),)


class FurniturePhotoNode:
    @classmethod
    def INPUT_TYPES(cls):
        url = "http://admin.qihuaimage.com/items/furniture_style"
        response = requests.get(url)
        response.raise_for_status()
        result = response.json()
        
        # å¤„ç†æ•°æ®ï¼šåˆ›å»ºå»é‡çš„parentnameåˆ—è¡¨å’Œä»¥parentnameä¸ºé”®çš„å­—å…¸
        data = result.get('data', [])
        
        # åˆ›å»ºå»é‡çš„parentnameåˆ—è¡¨
        parentname_list = list(set(item['parentname'] for item in data))
        parentname_list.sort()  # æ’åº
        
        # åˆ›å»ºä»¥parentnameä¸ºé”®ï¼Œtypenameåˆ—è¡¨ä¸ºå€¼çš„å­—å…¸
        parentname_dict = {}
        typename_list = []
        for item in data:
            typename = item['typename']
            if typename not in typename_list:
                typename_list.append(typename)
            parentname = item['parentname']
            typename = item['typename']
            if parentname not in parentname_dict:
                parentname_dict[parentname] = []
            parentname_dict[parentname].append(typename)
        
        # print("å»é‡çš„parentnameåˆ—è¡¨:", parentname_list)
        # print("parentnameå­—å…¸:", parentname_dict)
        
        return {
            "required": {
                "input_image": ("IMAGE",),  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
                "furniture_types": (parentname_list, {"default": parentname_list[0]}),
                "style_type": (typename_list, {"default": typename_list[0]}),
                # "resolution": (["1K", "2K", "4K"], {"default": "2K"}),
                "aspect_ratio": (["16:9","4:3","1:1", "3:4",  "9:16"], {"default": "4:3"}),
                "num_images": ("INT", {"default": 1, "min": 1, "max": 2}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Product&tool"

    def generate(self, seed, input_image, resolution="1K", aspect_ratio="4:3", num_images=1, furniture_types="", style_type=""):
        # è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()
        input_image_base64 = ImageConverter.tensor_to_base64(input_image)
        def call_api(seed_override):
            payload = {
                "model": "furniture-photo",
                "resolution": "2K",
                "aspect_ratio": aspect_ratio,
                "num_images": num_images,
                "furniture_types": furniture_types,
                "style_type": style_type,
                "seed": int(seed_override),
                "input_image": [input_image_base64],
            }
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=240)
            try:
                response.raise_for_status()
            except requests.exceptions.HTTPError as e:
                print(f"HTTPé”™è¯¯: {e}")
                print(f"å“åº”å†…å®¹: {response.text}")
                
                # å°è¯•è§£æé”™è¯¯ä¿¡æ¯
                try:
                    response_data = response.json()
                    if "error" in response_data and "message" in response_data["error"]:
                        error_message = response_data["error"]["message"]
                        # æå–JSONéƒ¨åˆ†ï¼ˆå»é™¤request idç­‰é¢å¤–ä¿¡æ¯ï¼‰
                        import re
                        json_match = re.search(r'\{.*\}', error_message)
                        if json_match:
                            json_str = json_match.group(0)
                            import json
                            error_json = json.loads(json_str)
                            if "error" in error_json:
                                print(f"å…·ä½“é”™è¯¯: {error_json['error']}")
                                if error_json["error"]:
                                    error_msg = error_json["error"]
                                else:
                                    error_msg = "server error,please try again laters"
                                error_tensor = ImageConverter.create_error_image(error_msg, 1024, 1024)
                                output_tensors.append(error_tensor)
                                return
                    raise
                except:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œå¿½ç•¥é”™è¯¯
                    error_msg = "server error,please try again laters"
                    error_tensor = ImageConverter.create_error_image(error_msg, 1024, 1024)
                    output_tensors.append(error_tensor)
                    return

            result = response.json()
            # print(result)
            image_url = result.get("res_url")

            if not image_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")

            image_urls = image_url.split("|") if image_url else []

            print(image_urls)
            for image_url in image_urls:
                if not image_url:
                    continue
                try:
                    # ä¸‹è½½å›¾ç‰‡
                    response = requests.get(image_url)
                    response.raise_for_status()
                    # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
                    img = Image.open(BytesIO(response.content)).convert("RGB")
                    output_tensors.append(ImageConverter.pil2tensor(img))
                except Exception as e:
                    print(f"ä¸‹è½½å›¾ç‰‡ {image_url} å¤±è´¥: {str(e)}")
                    error_tensor = ImageConverter.create_error_image("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                    output_tensors.append(error_tensor)
            if not output_tensors:
                error_tensor = ImageConverter.create_error_image("æœªè·å–åˆ°æœ‰æ•ˆå›¾ç‰‡ URL")
                output_tensors.append(error_tensor)
        output_tensors = []

        # è°ƒç”¨API
        call_api(seed)

        return (torch.cat(output_tensors, dim=0),)  # æ‹¼æ¥ä¸º (æ•°é‡, H, W, 3)


class DetailPhotoNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "input_image": ("IMAGE",),  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
                "mask": ("MASK",),  # è¾“å…¥é®ç½©
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Product&tool"

    def generate(self, seed, input_image=None, mask=None, num_images=1):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()
        if input_image is not None:
            # å°†å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒä»¥è·å–å°ºå¯¸
            pil_image = ImageConverter.tensor2pil(input_image)
            width, height = pil_image.size
            # print(f"åŸå§‹å›¾ç‰‡å°ºå¯¸: å®½åº¦={width}, é«˜åº¦={height}")
            
            # æ£€æŸ¥å¹¶è°ƒæ•´å›¾ç‰‡å°ºå¯¸ï¼Œç¡®ä¿å®½é«˜åœ¨1280åˆ°4096ä¹‹é—´
            min_size, max_size = 1280, 4096
            needs_resize = False
            scale_factor = 1.0
            
            # å¦‚æœå®½åº¦æˆ–é«˜åº¦å°äºæœ€å°å€¼ï¼Œéœ€è¦æ”¾å¤§
            if width < min_size or height < min_size:
                # è®¡ç®—æ”¾å¤§æ¯”ä¾‹ï¼Œå–ä¸¤ä¸ªæ–¹å‘ä¸­è¾ƒå¤§çš„æ¯”ä¾‹
                scale_factor = max(min_size / width, min_size / height)
                needs_resize = True
            
            # å¦‚æœå®½åº¦æˆ–é«˜åº¦å¤§äºæœ€å¤§å€¼ï¼Œéœ€è¦ç¼©å°
            elif width > max_size or height > max_size:
                # è®¡ç®—ç¼©å°æ¯”ä¾‹ï¼Œå–ä¸¤ä¸ªæ–¹å‘ä¸­è¾ƒå°çš„æ¯”ä¾‹
                scale_factor = min(max_size / width, max_size / height)
                needs_resize = True
            
            # å¦‚æœéœ€è¦è°ƒæ•´å°ºå¯¸
            if needs_resize:
                new_width = int(width * scale_factor)
                new_height = int(height * scale_factor)
                #print(f"è°ƒæ•´å›¾ç‰‡å°ºå¯¸: å®½åº¦={new_width}, é«˜åº¦={new_height}, ç¼©æ”¾æ¯”ä¾‹={scale_factor:.2f}")
                
                # ä½¿ç”¨LANCZOSé‡é‡‡æ ·æ–¹æ³•è¿›è¡Œé«˜è´¨é‡ç¼©æ”¾
                pil_image = pil_image.resize((new_width, new_height), Image.LANCZOS)
                
                # å°†è°ƒæ•´åçš„PILå›¾åƒè½¬æ¢å›å¼ é‡
                input_image = ImageConverter.pil2tensor(pil_image)
            
            # è·å–æœ€ç»ˆå°ºå¯¸ç”¨äºAPIè¯·æ±‚
            final_width, final_height = pil_image.size
            size = f"{final_width}x{final_height}"
            # print(f"æœ€ç»ˆå›¾ç‰‡å°ºå¯¸: {size}")
        # åˆå¹¶å›¾åƒå’Œé®ç½©
        merged_image = ImageConverter.highlight_mask_with_rectangle(input_image, mask)

        payload = {
            "model": "detail-photo",
            "seed": int(seed+6),
            "watermark": False,
            "max_SetImage": num_images,
            "input_image": [merged_image],
            "DetailPhoto": True,
            "size": size,
        }


        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }
        response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
        # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
        if response.status_code != 200:
            error_msg = ImageConverter.get_status_error_msg(response)
            print("é”™è¯¯ä¿¡æ¯",error_msg)
            output_tensors = []
            error_tensor = ImageConverter.create_error_image(error_msg)
            output_tensors.append(error_tensor)
            return (torch.cat(output_tensors, dim=0),)
        response.raise_for_status()
        result = response.json()

        # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
        res_url = result.get("res_url", "")
        if not res_url:
            raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
        image_urls = res_url.split("|") if res_url else []

        api_tensors = []
        print(image_urls)
        for image_url in image_urls:
            if not image_url:
                continue
            try:
                # ä¸‹è½½å›¾ç‰‡
                response = requests.get(image_url)
                response.raise_for_status()
                # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
                img = Image.open(BytesIO(response.content)).convert("RGB")
                api_tensors.append(ImageConverter.pil2tensor(img))
            except Exception as e:
                print(f"ä¸‹è½½å›¾ç‰‡ {image_url} å¤±è´¥: {str(e)}")
                error_tensor = ImageConverter.create_error_image("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                api_tensors.append(error_tensor)

        if not api_tensors:
            error_tensor = ImageConverter.create_error_image("æœªè·å–åˆ°æœ‰æ•ˆå›¾ç‰‡ URL")
            api_tensors.append(error_tensor)

        return (torch.cat(api_tensors, dim=0),)



class DetailJinNode:
    @classmethod
    def INPUT_TYPES(cls):
        url = "http://admin.qihuaimage.com/items/furn_cai"
        response = requests.get(url)
        response.raise_for_status()
        result = response.json()
        data = result.get('data', [])
        Polished_list = list(set(item['name'] for item in data))
        return {
            "required": {
                "input_image": ("IMAGE",),  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
                "Polished_type": (Polished_list, {"default": Polished_list[0]}),
                "num_images": ("INT", {"default": 1, "min": 1, "max": 2}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Product&tool"

    def generate(self, seed, input_image=None,Polished_type="é‡‘å±&æœ¨çº¹",num_images=1):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()
        
        # è·å–å›¾ç‰‡çš„é•¿å®½
        if input_image is not None:
            # å°†å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒä»¥è·å–å°ºå¯¸
            pil_image = ImageConverter.tensor2pil(input_image)
            width, height = pil_image.size
            # print(f"åŸå§‹å›¾ç‰‡å°ºå¯¸: å®½åº¦={width}, é«˜åº¦={height}")
            
            # æ£€æŸ¥å¹¶è°ƒæ•´å›¾ç‰‡å°ºå¯¸ï¼Œç¡®ä¿å®½é«˜åœ¨1280åˆ°4096ä¹‹é—´
            min_size, max_size = 1280, 4096
            needs_resize = False
            scale_factor = 1.0
            
            # å¦‚æœå®½åº¦æˆ–é«˜åº¦å°äºæœ€å°å€¼ï¼Œéœ€è¦æ”¾å¤§
            if width < min_size or height < min_size:
                # è®¡ç®—æ”¾å¤§æ¯”ä¾‹ï¼Œå–ä¸¤ä¸ªæ–¹å‘ä¸­è¾ƒå¤§çš„æ¯”ä¾‹
                scale_factor = max(min_size / width, min_size / height)
                needs_resize = True
            
            # å¦‚æœå®½åº¦æˆ–é«˜åº¦å¤§äºæœ€å¤§å€¼ï¼Œéœ€è¦ç¼©å°
            elif width > max_size or height > max_size:
                # è®¡ç®—ç¼©å°æ¯”ä¾‹ï¼Œå–ä¸¤ä¸ªæ–¹å‘ä¸­è¾ƒå°çš„æ¯”ä¾‹
                scale_factor = min(max_size / width, max_size / height)
                needs_resize = True
            
            # å¦‚æœéœ€è¦è°ƒæ•´å°ºå¯¸
            if needs_resize:
                new_width = int(width * scale_factor)
                new_height = int(height * scale_factor)
                # print(f"è°ƒæ•´å›¾ç‰‡å°ºå¯¸: å®½åº¦={new_width}, é«˜åº¦={new_height}, ç¼©æ”¾æ¯”ä¾‹={scale_factor:.2f}")
                
                # ä½¿ç”¨LANCZOSé‡é‡‡æ ·æ–¹æ³•è¿›è¡Œé«˜è´¨é‡ç¼©æ”¾
                pil_image = pil_image.resize((new_width, new_height), Image.LANCZOS)
                
                # å°†è°ƒæ•´åçš„PILå›¾åƒè½¬æ¢å›å¼ é‡
                input_image = ImageConverter.pil2tensor(pil_image)
            
            # è·å–æœ€ç»ˆå°ºå¯¸ç”¨äºAPIè¯·æ±‚
            final_width, final_height = pil_image.size
            size = f"{final_width}x{final_height}"
            # print(f"æœ€ç»ˆå›¾ç‰‡å°ºå¯¸: {size}")
        
        merged_image = ImageConverter.tensor_to_base64(input_image)

        payload = {
            "model": "detail-jin",
            "seed": int(seed+6),
            "max_SetImage": num_images,
            "input_image": [merged_image],
            "Polished-type": Polished_type,
            "size": size,
        }


        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }
        response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
        # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
        if response.status_code != 200:
            error_msg = ImageConverter.get_status_error_msg(response)
            print("é”™è¯¯ä¿¡æ¯",error_msg)
            output_tensors = []
            error_tensor = ImageConverter.create_error_image(error_msg)
            output_tensors.append(error_tensor)
            return (torch.cat(output_tensors, dim=0),)
        response.raise_for_status()
        result = response.json()

        # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
        res_url = result.get("res_url", "")
        if not res_url:
            raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
        image_urls = res_url.split("|") if res_url else []

        api_tensors = []
        print(image_urls)
        for image_url in image_urls:
            if not image_url:
                continue
            try:
                # ä¸‹è½½å›¾ç‰‡
                response = requests.get(image_url)
                response.raise_for_status()
                # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
                img = Image.open(BytesIO(response.content)).convert("RGB")
                api_tensors.append(ImageConverter.pil2tensor(img))
            except Exception as e:
                print(f"ä¸‹è½½å›¾ç‰‡ {image_url} å¤±è´¥: {str(e)}")
                error_tensor = ImageConverter.create_error_image("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                api_tensors.append(error_tensor)

        if not api_tensors:
            error_tensor = ImageConverter.create_error_image("æœªè·å–åˆ°æœ‰æ•ˆå›¾ç‰‡ URL")
            api_tensors.append(error_tensor)

        return (torch.cat(api_tensors, dim=0),)




class FurnitureAngleNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "input_image": ("IMAGE",),  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
                "angle_type": (["4k-ä¿¯è§†45åº¦","4K-æ­£è§†è§’","4k-é¡¶è§†å›¾","4K-å¯¹è§’çº¿æ‹æ‘„","1k-å·¦ä¾§å‚ç›´è§†å›¾","1k-å³ä¾§å‚ç›´è§†å›¾"], {"default": "2k-ä¿¯è§†45åº¦"}),
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Product&tool"

    def generate(self, seed, input_image=None,angle_type="2k-ä¿¯è§†45åº¦",num_images=1):
        # åˆå§‹åŒ–é»˜è®¤å®½é«˜
        width = 1024
        height = 1024
        
        # ä»input_imageä¸­è·å–å®½é«˜
        if input_image is not None:
            # å°†å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ
            pil_image = ImageConverter.tensor2pil(input_image)
            if pil_image is not None:
                width = pil_image.width
                height = pil_image.height
        
        min_pixels = 3986400  # 2560x1440
        max_pixels = 16777216  # 4096x4096
        
        # è®¡ç®—å½“å‰æ€»åƒç´ æ•°
        current_pixels = width * height
        
        # 1. é¦–å…ˆå¤„ç†æ€»åƒç´ æ•°ä¸æ»¡è¶³çš„æƒ…å†µ
        if current_pixels < min_pixels:
            scale_ratio = (min_pixels / current_pixels) ** 0.5
            width = int(width * scale_ratio)
            height = int(height * scale_ratio)
            current_pixels = width * height  # æ›´æ–°å½“å‰åƒç´ æ•°

        if current_pixels > max_pixels:
            # éœ€è¦ç¼©å°ï¼Œè®¡ç®—ç¼©å°æ¯”ä¾‹
            scale_ratio = (max_pixels / current_pixels) ** 0.5
            width = int(width * scale_ratio)
            height = int(height * scale_ratio)
            current_pixels = width * height  # æ›´æ–°å½“å‰åƒç´ æ•°
        
        # print("å¤„ç†åçš„å›¾ç‰‡å®½é«˜",f"{width}x{height}")
            

                
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()
        # åˆå¹¶å›¾åƒå’Œé®ç½©
        merged_image = ImageConverter.tensor_to_base64(input_image)
        
        def cell(num):
            payload = {
                "model": "furniture-angle",
                "input_image": [merged_image],
                "angle_type": angle_type,
                "seed": int(seed+num),
                "watermark": False,
                "max_SetImage": num_images,
                "pro": True,
                "size": f"{width}x{height}",
            }

            if "1k" in angle_type:
                payload["model"] = "multiple-angles"
                payload["input_image"] = [merged_image]
                payload["rotate_right_left"] = float(-90) if "å³ä¾§" in angle_type else float(90)
                payload["num_images"] = num_images

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                print("é”™è¯¯ä¿¡æ¯",error_msg)
                output_tensors = []
                error_tensor = ImageConverter.create_error_image(error_msg)
                output_tensors.append(error_tensor)
                return (torch.cat(output_tensors, dim=0),)
            response.raise_for_status()
            result = response.json()

            # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
            res_url = result.get("res_url", "")
            if not res_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
            image_urls = res_url.split("|") if res_url else []

            print(image_urls)
            for image_url in image_urls:
                if not image_url:
                    continue
                try:
                    # ä¸‹è½½å›¾ç‰‡
                    response = requests.get(image_url)
                    response.raise_for_status()
                    # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
                    img = Image.open(BytesIO(response.content)).convert("RGB")
                    api_tensors.append(ImageConverter.pil2tensor(img))
                except Exception as e:
                    print(f"ä¸‹è½½å›¾ç‰‡ {image_url} å¤±è´¥: {str(e)}")
                    error_tensor = ImageConverter.create_error_image("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                    api_tensors.append(error_tensor)
        api_tensors = []
        cell(1)
        if "2k" in angle_type and num_images == 2:
            cell(2)
        if not api_tensors:
            error_tensor = ImageConverter.create_error_image("æœªè·å–åˆ°æœ‰æ•ˆå›¾ç‰‡ URL")
            api_tensors.append(error_tensor)

        return (torch.cat(api_tensors, dim=0),)




class NanoProNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "is_translation": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                # "limit_generations": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "resolution": (["1K", "2K", "4K"], {"default": "2K"}),
                "aspect_ratio": (["auto","16:9","4:3","2:3","4:5","1:1","3:2","5:4","3:4", "9:16"], {"default": "auto"}),
                "num_images": ("INT", {"default": 1, "min": 1, "max": 2}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
                "seed": ("INT", {"default": -1}),
            },
            "optional": {
                "input_images": ("IMAGE",),  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/ImageCreat"

    def generate(self, seed, input_images=None, resolution="1K", aspect_ratio="auto", is_translation=False, limit_generations=False, prompt="", num_images=1):
        # è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()
        def call_api(seed_override):
            payload = {
                "model": "nano-banana-pro",
                "resolution": resolution,
                "aspect_ratio": aspect_ratio,
                "prompt": prompt,
                "is_translation": is_translation,
                "limit_generations": limit_generations,
                "seed": int(seed_override),
                "num_images": int(num_images),
            }
            if input_images is None and aspect_ratio == "auto":
                payload["aspect_ratio"] = "1:1"
            if input_images is not None:
                # æ£€æŸ¥å›¾åƒé•¿è¾¹æ˜¯å¦å¤§äº1280ï¼Œå¦‚æœæ˜¯åˆ™ç­‰æ¯”å‹ç¼©
                compressed_images = []
                for img in input_images:
                    # å°†å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ
                    pil_image = ImageConverter.tensor2pil(img)
                    if pil_image is not None:
                        # æ£€æŸ¥é•¿è¾¹
                        width, height = pil_image.size
                        max_size = max(width, height)
                        
                        if max_size > 1280:
                            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
                            scale = 1280 / max_size
                            new_width = int(width * scale)
                            new_height = int(height * scale)
                            # ä½¿ç”¨é«˜è´¨é‡çš„é‡é‡‡æ ·æ–¹æ³•è¿›è¡Œç¼©æ”¾
                            pil_image = pil_image.resize((new_width, new_height), Image.LANCZOS)
                        
                        # å°†å¤„ç†åçš„å›¾åƒè½¬æ¢å›å¼ é‡
                        compressed_tensor = ImageConverter.pil2tensor(pil_image)
                        compressed_images.append(compressed_tensor)
                
                input_image_base64 = ImageConverter.convert_images_to_base64(compressed_images)
                payload["input_image"] = input_image_base64
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=240)

            response.raise_for_status()

            result = response.json()
            image_url = result.get("res_url")

            if not image_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")

            image_urls = image_url.split("|") if image_url else []

            print(image_urls)
            for image_url in image_urls:
                if not image_url:
                    continue
                try:
                    # ä¸‹è½½å›¾ç‰‡
                    response = requests.get(image_url)
                    response.raise_for_status()
                    # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
                    img = Image.open(BytesIO(response.content)).convert("RGB")
                    output_tensors.append(ImageConverter.pil2tensor(img))
                except Exception as e:
                    print(f"ä¸‹è½½å›¾ç‰‡ {image_url} å¤±è´¥: {str(e)}")
                    error_tensor = ImageConverter.create_error_image("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                    output_tensors.append(error_tensor)
            if not output_tensors:
                error_tensor = ImageConverter.create_error_image("æœªè·å–åˆ°æœ‰æ•ˆå›¾ç‰‡ URL")
                output_tensors.append(error_tensor)
        output_tensors = []

        # è°ƒç”¨API
        call_api(seed)

        return (torch.cat(output_tensors, dim=0),)  # æ‹¼æ¥ä¸º (æ•°é‡, H, W, 3)



class Flux2Node:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "is_translation": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "aspect_ratio": (["auto","16:9","4:3","1:1", "3:4",  "9:16"], {"default": "auto"}),
                "custom_size": ("BOOLEAN", {"default": False}),  # è‡ªå®šä¹‰å°ºå¯¸å¼€å…³
                "width": ("INT", {"default": 1024, "min": 1024, "max": 2048}),  # ç”Ÿæˆå¼ æ•°
                "height": ("INT", {"default": 1024, "min": 1024, "max": 2048}),  # ç”Ÿæˆå¼ æ•°
                "seed": ("INT", {"default": -1}),
            },
            "optional": {
                "input_images": ("IMAGE",),  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/ImageCreat"

    def generate(self, seed, input_images=None,prompt="",num_images=1,is_translation=False,aspect_ratio="auto",custom_size=False,width=1024,height=1024):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        def cell(num):
            payload = {
                "model": "flux2",
                "prompt": prompt,
                "num_images": num_images,
                "is_translation": is_translation,
                "aspect_ratio": aspect_ratio,
                "seed": int(seed+num),
            }
            if custom_size:
                payload["width"] = width
                payload["height"] = height
            if input_images is None and aspect_ratio == "auto":
                payload["aspect_ratio"] = "4:3"
            if input_images is not None:
                input_image_base64 = ImageConverter.convert_images_to_base64(input_images)
                payload["input_image"] = input_image_base64

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                print("é”™è¯¯ä¿¡æ¯",error_msg)
                output_tensors = []
                error_tensor = ImageConverter.create_error_image(error_msg)
                output_tensors.append(error_tensor)
                return (torch.cat(output_tensors, dim=0),)
            response.raise_for_status()
            result = response.json()

            # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
            res_url = result.get("res_url", "")
            if not res_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
            image_urls = res_url.split("|") if res_url else []

            print(image_urls)
            for image_url in image_urls:
                if not image_url:
                    continue
                try:
                    # ä¸‹è½½å›¾ç‰‡
                    response = requests.get(image_url)
                    response.raise_for_status()
                    # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
                    img = Image.open(BytesIO(response.content)).convert("RGB")
                    api_tensors.append(ImageConverter.pil2tensor(img))
                except Exception as e:
                    print(f"ä¸‹è½½å›¾ç‰‡ {image_url} å¤±è´¥: {str(e)}")
                    error_tensor = ImageConverter.create_error_image("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                    api_tensors.append(error_tensor)
        api_tensors = []
        cell(1)
        if not api_tensors:
            error_tensor = ImageConverter.create_error_image("æœªè·å–åˆ°æœ‰æ•ˆå›¾ç‰‡ URL")
            api_tensors.append(error_tensor)

        return (torch.cat(api_tensors, dim=0),)


# ç¡®ä¿ComfyUIçš„æ ¸å¿ƒæ¨¡å—èƒ½è¢«å¯¼å…¥
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), "..", ".."))
from typing import Any, Dict, List
# ComfyUIæ ¸å¿ƒèŠ‚ç‚¹åŸºç±»ï¼ˆä¸åŒç‰ˆæœ¬è·¯å¾„å¯èƒ½ç•¥æœ‰å·®å¼‚ï¼‰
try:
    from nodes import NODE_CLASS_MAPPINGS, NODE_DISPLAY_NAME_MAPPINGS
except ImportError:
    NODE_CLASS_MAPPINGS = {}
    NODE_DISPLAY_NAME_MAPPINGS = {}

# --------------------------
# åŸºç¡€æ–‡ä»¶åŠ è½½èŠ‚ç‚¹ï¼ˆè§£å†³FILEè¾“å…¥é—®é¢˜ï¼‰
# --------------------------
class FileLoaderNode:
    """æ–‡ä»¶åŠ è½½èŠ‚ç‚¹ï¼šç‚¹å‡»å¼¹å‡ºç³»ç»Ÿæ–‡ä»¶é€‰æ‹©æ¡†ï¼Œæ”¯æŒdocx/pdfç­‰æ–‡ä»¶"""
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                "file_path": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "widget": "string",  # ä½¿ç”¨æ ‡å‡†string widgetï¼Œé…åˆJavaScriptæ·»åŠ ä¸Šä¼ æŒ‰é’®
                    "placeholder": "æ–‡ä»¶è·¯å¾„æˆ–ç‚¹å‡»ä¸Šä¼ æŒ‰é’®é€‰æ‹©æ–‡ä»¶"
                }),
            }
        }

    RETURN_TYPES = ("FILE",)
    RETURN_NAMES = ("file",)
    FUNCTION = "load_file"
    CATEGORY = "ğŸ¨MJapiparty/LLM"
    DISPLAY_NAME = "æ–‡ä»¶åŠ è½½å™¨ï¼ˆPDF/Wordï¼‰"

    def load_file(self, file_path: str) -> tuple:
        if not os.path.exists(file_path):
            raise ValueError(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")
        allowed_extensions = (".docx", ".pdf", ".doc")
        if not file_path.lower().endswith(allowed_extensions):
            raise ValueError(f"ä»…æ”¯æŒä»¥ä¸‹æ–‡ä»¶ç±»å‹ï¼š{allowed_extensions}")
        return (file_path,)




class GeminiLLMNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", ),
                # "limit_generations": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "model": (["Gemini 3 Pro Preview", "Gemini 3 Flash Preview"], {"default": "Gemini 3 Flash Preview"}),  # å€¼éœ€å’Œåç«¯ MODEL_MAPPING çš„ key å®Œå…¨ä¸€è‡´
                "media_resolution": (["Default","Low","Medium","High"], {"default": "Default"}),  # å€¼éœ€å’Œåç«¯ RESOLUTION_MAPPING çš„ key å®Œå…¨ä¸€è‡´
                "thinking_level": (["Minimal","Low","Medium","High"], {"default": "High"}),  # å€¼éœ€å’Œåç«¯ THINKING_LEVEL_MAPPING çš„ key å®Œå…¨ä¸€è‡´
                "System_prompt": ("STRING", {"default": ""}),
                "Web_search": ("BOOLEAN", {"default": True}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "format": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "seed": ("INT", {"default": -1}),
            },
            "optional": {
                "image_input": ("IMAGE",),  # æ”¯æŒå¤šè¾“å…¥ï¼Œä¼ é€’æ—¶ä¼šè½¬ä¸º base64 åˆ—è¡¨
                "video": ("VIDEO",),  # æ”¯æŒå¤šè¾“å…¥ï¼Œä¼ é€’æ—¶ä¼šè½¬ä¸º base64 åˆ—è¡¨ï¼ˆæ‹†å¸§åï¼‰
                "file": ("FILE",),  # æ”¯æŒå¤šè¾“å…¥ï¼Œä¼ é€’æ—¶ä¼šè½¬ä¸º base64 åˆ—è¡¨
                "context": ("ANY",),  # æ¥æ”¶å¯¹è¯å†å²ä¸Šä¸‹æ–‡æ•°æ®
            }
        }

    # è¿”å›å­—ç¬¦ä¸²æ–‡æœ¬
    RETURN_TYPES = ("STRING","ANY")  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªSTRING
    RETURN_NAMES = ("output","context")  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/LLM"


    def generate(self, seed, prompt="", model="Gemini 3 Flash Preview Free", media_resolution="Default", thinking_level="High", System_prompt="", Web_search=True, format=False, image_input=None, video=None, file=None, context=None):
        # è¾“å…¥éç©ºæ ¡éªŒ - æ›´ä¸¥æ ¼åœ°æ£€æŸ¥promptæ˜¯å¦ä¸ºç©º
        prompt_stripped = prompt.strip() if prompt else ""
        if not prompt_stripped and not image_input and not video and not file:
            return ("é”™è¯¯ï¼šè‡³å°‘éœ€è¦è¾“å…¥æ–‡æœ¬ã€å›¾ç‰‡ã€è§†é¢‘æˆ–æ–‡ä»¶ä¸­çš„ä¸€ç§",)

        if context is not None:
            conversation_history = context.get("llm", [])
        else:
            conversation_history = []

        # å‚æ•°å€¼æ ¡éªŒ
        valid_models = ["Gemini 3 Pro Preview", "Gemini 3 Flash Preview", "Gemini 3 Flash Preview Free"]
        valid_resolutions = ["Default", "Low", "Medium", "High"]
        valid_thinking_levels = ["Minimal", "Low", "Medium", "High"]
        
        if model not in valid_models:
            return (f"é”™è¯¯ï¼šæ— æ•ˆçš„æ¨¡å‹é€‰æ‹©ï¼Œå¯é€‰å€¼ä¸ºï¼š{', '.join(valid_models)}",)
        
        if media_resolution not in valid_resolutions:
            return (f"é”™è¯¯ï¼šæ— æ•ˆçš„åˆ†è¾¨ç‡é€‰æ‹©ï¼Œå¯é€‰å€¼ä¸ºï¼š{', '.join(valid_resolutions)}",)
        
        if thinking_level not in valid_thinking_levels:
            return (f"é”™è¯¯ï¼šæ— æ•ˆçš„æ€ç»´æ°´å¹³é€‰æ‹©ï¼Œå¯é€‰å€¼ä¸ºï¼š{', '.join(valid_thinking_levels)}",)
        
        # è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()
        # å¤„ç†å›¾ç‰‡è¾“å…¥
        input_image_base64 = None
        if image_input is not None:
            try:
                input_image_base64 = ImageConverter.convert_images_to_base64(image_input)
                if not input_image_base64:
                    return ("é”™è¯¯ï¼šå›¾ç‰‡è½¬æ¢ä¸ºbase64å¤±è´¥",)
            except Exception as e:
                return (f"é”™è¯¯ï¼šå›¾ç‰‡å¤„ç†å¤±è´¥ï¼š{str(e)}",)
        
        # å¤„ç†è§†é¢‘è¾“å…¥
        video_base64 = None
        if video is not None:
            try:
                # ç¡®ä¿videoæ˜¯åˆ—è¡¨å½¢å¼
                video_list = [video] if not isinstance(video, list) else video
                video_base64 = ImageConverter.video_to_full_base64_list(video_list)
                if not video_base64:
                    return ("é”™è¯¯ï¼šè§†é¢‘è½¬å¸§æˆ–base64è½¬æ¢å¤±è´¥",)
            except Exception as e:
                return (f"é”™è¯¯ï¼šè§†é¢‘å¤„ç†å¤±è´¥ï¼š{str(e)}",)
        
        # å¤„ç†æ–‡ä»¶è¾“å…¥
        file_base64 = None
        if file is not None:
            try:
                # ç¡®ä¿fileæ˜¯åˆ—è¡¨å½¢å¼
                file_list = [file] if not isinstance(file, list) else file
                file_base64 = ImageConverter.files_to_base64_list(file_list)
                if not file_base64:
                    return ("é”™è¯¯ï¼šæ–‡ä»¶è½¬base64å¤±è´¥",)
            except Exception as e:
                return (f"é”™è¯¯ï¼šæ–‡ä»¶å¤„ç†å¤±è´¥ï¼š{str(e)}",)
        
        # è®°å½•å¤„ç†çš„åª’ä½“æ–‡ä»¶æ•°é‡
        print(f"å¤„ç†åª’ä½“æ–‡ä»¶æ•°é‡: å›¾ç‰‡{len(input_image_base64) if input_image_base64 else 0}å¼ , è§†é¢‘å¸§{len(video_base64) if video_base64 else 0}å¸§, æ–‡ä»¶{len(file_base64) if file_base64 else 0}ä¸ª")
        
        def call_api(seed_override):
            MODEL_MAPPING = {
                "Gemini 3 Pro Preview": "Gemini-3-Pro-Preview",
                "Gemini 3 Flash Preview": "Gemini-3-Flash-Preview",
            }
            modelr = MODEL_MAPPING.get(model, model)
            print("=== å‡†å¤‡è°ƒç”¨API ===")
            # æ„å»ºpayloadï¼ŒåŒ…å«æ‰€æœ‰å‚æ•°
            nonlocal conversation_history  # å…è®¸åœ¨å†…éƒ¨å‡½æ•°ä¸­ä¿®æ”¹å¤–éƒ¨å˜é‡
            payload = {
                "model": modelr,
                "prompt": prompt,
                "seed": int(seed_override),
                "model_type": model,
                "media_resolution": media_resolution,
                "thinking_level": thinking_level,
                "system_prompt": System_prompt,
                "web_search": Web_search,
                "format": format,
                "conversation_history": conversation_history,
            }
            
            # æ·»åŠ å›¾ç‰‡è¾“å…¥ï¼ˆå¦‚æœæœ‰ï¼‰
            if input_image_base64 is not None:
                payload["input_image"] = input_image_base64
                print(f"APIè¯·æ±‚åŒ…å«å›¾ç‰‡: {len(input_image_base64)}å¼ ")
            
            # æ·»åŠ è§†é¢‘è¾“å…¥ï¼ˆå¦‚æœæœ‰ï¼‰
            if video_base64 is not None:
                payload["video"] = video_base64
                print(f"APIè¯·æ±‚åŒ…å«è§†é¢‘å¸§: {len(video_base64)}å¸§")
            
            # æ·»åŠ æ–‡ä»¶è¾“å…¥ï¼ˆå¦‚æœæœ‰ï¼‰
            if file_base64 is not None:
                payload["file"] = file_base64
                print(f"APIè¯·æ±‚åŒ…å«æ–‡ä»¶: {len(file_base64)}ä¸ª")
            
            # æ—¥å¿—ï¼šæ‰“å°APIè¯·æ±‚åŸºæœ¬ä¿¡æ¯ï¼ˆä¸åŒ…å«å¤§çš„base64æ•°æ®ï¼‰
            payload_info = {
                "model": payload["model"],
                "model_type": payload["model_type"],
                "seed": payload["seed"],
                "has_prompt": bool(payload["prompt"].strip()),
                "has_system_prompt": bool(payload["system_prompt"].strip()),
                "web_search": payload["web_search"],
                "format": payload["format"],
                "media_resolution": payload["media_resolution"],
                "thinking_level": payload["thinking_level"],
                "has_images": "input_image" in payload,
                "has_videos": "video" in payload,
                "has_files": "file" in payload
            }
            print(f"APIè¯·æ±‚å‚æ•°: {payload_info}")
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            print(f"æ­£åœ¨è°ƒç”¨API: {oneapi_url}")
            print(f"APIè°ƒç”¨è¶…æ—¶è®¾ç½®: 240ç§’")
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=240)
            print(f"APIè°ƒç”¨å®Œæˆï¼ŒçŠ¶æ€ç : {response.status_code}")

            response.raise_for_status()

            result = response.json()
            print(f"APIå“åº”ç»“æ„: {list(result.keys())}")
            restext = result.get("restext", "")
            conversation_history = result.get("conversation_history", [])  # æå–å¯¹è¯å†å²
            if conversation_history:
                # print(f"APIè¿”å›å¯¹è¯å†å²: {conversation_history}")
                ImageConverter.conversation_context["llm"] = conversation_history
                conversation_history = {
                    "llm": conversation_history
                }
                # print("ContextNode ä¿å­˜å¯¹è¯å†å²:", ImageConverter.conversation_context)
            
            if not restext:
                print("è­¦å‘Šï¼šAPIå“åº”ä¸­restextå­—æ®µä¸ºç©º")
                restext = "æœªæ‰¾åˆ°å“åº”æ–‡æœ¬"
            else:
                print(f"APIè¿”å›restextï¼Œé•¿åº¦: {len(restext)}å­—ç¬¦")
            
            return restext
        try:
            print("=== æ‰§è¡ŒAPIè°ƒç”¨ ===")
            # è°ƒç”¨API
            restext = call_api(seed)
            print("=== GeminiLLMNode æ‰§è¡Œå®Œæˆ ===")
            return (restext,conversation_history)
        except requests.exceptions.RequestException as e:
            print(f"=== APIè°ƒç”¨å¤±è´¥ ===")
            print(f"é”™è¯¯ç±»å‹: è¯·æ±‚å¼‚å¸¸")
            print(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"é”™è¯¯çŠ¶æ€ç : {e.response.status_code}")
                try:
                    error_response = e.response.json()
                    print(f"é”™è¯¯å“åº”å†…å®¹: {error_response}")
                except:
                    print(f"é”™è¯¯å“åº”æ–‡æœ¬: {e.response.text[:500]}...")
            # è¿”å›é”™è¯¯ä¿¡æ¯ä½œä¸ºå­—ç¬¦ä¸²
            return (f"APIè°ƒç”¨å¤±è´¥: {str(e)}",)
        except Exception as e:
            print(f"=== GeminiLLMNode æ‰§è¡Œå¤±è´¥ ===")
            print(f"é”™è¯¯ç±»å‹: å…¶ä»–å¼‚å¸¸")
            print(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
            # è¿”å›é”™è¯¯ä¿¡æ¯ä½œä¸ºå­—ç¬¦ä¸²
            return (f"APIè°ƒç”¨å¤±è´¥: {str(e)}",)




class Gemini3NanoNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", ),
                "model": (["Gemini 2.5 Flash Image", "Gemini-3-pro-image-preview"], {"default": "Gemini 2.5 Flash Image"}),  # å€¼éœ€å’Œåç«¯ MODEL_MAPPING çš„ key å®Œå…¨ä¸€è‡´
                "media_resolution": (["Default","Low","Medium","High"], {"default": "Default"}),  # å€¼éœ€å’Œåç«¯ RESOLUTION_MAPPING çš„ key å®Œå…¨ä¸€è‡´
                "thinking_level": (["minimal","low","medium","high"], {"default": "high"}),  # å€¼éœ€å’Œåç«¯ THINKING_LEVEL_MAPPING çš„ key å®Œå…¨ä¸€è‡´
                "safe_level": (["high","medium","low"], {"default": "medium"}),  # å€¼éœ€å’Œåç«¯ THINKING_LEVEL_MAPPING çš„ key å®Œå…¨ä¸€è‡´
                "resolution": (["1K", "2K", "4K"], {"default": "1K"}),
                "aspect_ratio": (["16:9","4:3","2:3","4:5","1:1","3:2","5:4","3:4", "9:16"], {"default": "1:1"}),
                "System_prompt": ("STRING", {"default": ""}),
                "Web_search": ("BOOLEAN", {"default": True}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "seed": ("INT", {"default": -1}),
            },
            "optional": {
                "input_images": ("IMAGE",),  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
                "context": ("ANY",),  # æ¥æ”¶å¯¹è¯å†å²ä¸Šä¸‹æ–‡æ•°æ®
            }
        }

    RETURN_TYPES = ("IMAGE","STRING", "ANY")  # è¿”å›å›¾ç‰‡å’Œå¯¹è¯å†å²ï¼ˆANYç±»å‹å…¼å®¹conversation_historyæ•°ç»„ï¼‰
    RETURN_NAMES = ("image", "text", "context")  # è¾“å‡ºç«¯å£åç§°
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/LLM"

    def generate(self, seed, input_images=None, resolution="1K", aspect_ratio="1:1",  prompt="", safe_level="medium", thinking_level="High", System_prompt="", Web_search=True, model="Gemini 2.5 Flash Image", context=None, media_resolution="Default"):
        # è·å–é…ç½®
        from PIL import Image
        oneapi_url, oneapi_token = config_manager.get_api_config()
        # å¦‚æœæ²¡æœ‰æä¾›å¯¹è¯å†å²ï¼Œåˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
        if context is not None:
            conversation_history = context.get("image", [])
        else:
            conversation_history = []
        MODEL_MAPPING = {
            "Gemini 2.5 Flash Image": "Gemini2.5-image-Nanobanana",
            "Gemini-3-pro-image-preview": "Gemini3-image-Nanobanana-pro",
        }
        modelr = MODEL_MAPPING.get(model, model)
        output_tensors = []
        payload = {
            "model": modelr,
            "modelr": model,
            "resolution": resolution,
            "media_resolution": media_resolution,
            "prompt": prompt,
            "seed": 666,
            "safe_level": safe_level,
            "System_prompt": System_prompt,
            "Web_search": Web_search,
            "aspect_ratio": aspect_ratio,
            "conversation_history": conversation_history,  # å‘é€APIè¯·æ±‚æ—¶å¸¦ä¸Šä¸Šä¸‹æ–‡æ•°æ®
        }
        if model != "Gemini 2.5 Flash Image":
            payload["thinking_level"] = thinking_level 
        if input_images is not None:
            # æ£€æŸ¥å›¾åƒé•¿è¾¹æ˜¯å¦å¤§äº1280ï¼Œå¦‚æœæ˜¯åˆ™ç­‰æ¯”å‹ç¼©
            compressed_images = []
            for img in input_images:
                # å°†å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ
                pil_image = ImageConverter.tensor2pil(img)
                if pil_image is not None:
                    # æ£€æŸ¥é•¿è¾¹
                    width, height = pil_image.size
                    max_size = max(width, height)
                    
                    if max_size > 1280:
                        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
                        scale = 1280 / max_size
                        new_width = int(width * scale)
                        new_height = int(height * scale)
                        # ä½¿ç”¨é«˜è´¨é‡çš„é‡é‡‡æ ·æ–¹æ³•è¿›è¡Œç¼©æ”¾
                        pil_image = pil_image.resize((new_width, new_height), Image.LANCZOS)
                    
                    # å°†å¤„ç†åçš„å›¾åƒè½¬æ¢å›å¼ é‡
                    compressed_tensor = ImageConverter.pil2tensor(pil_image)
                    compressed_images.append(compressed_tensor)
            
            input_image_base64 = ImageConverter.convert_images_to_base64(compressed_images)
            payload["input_image"] = input_image_base64
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }
        response = requests.post(oneapi_url, headers=headers, json=payload, timeout=240)

        response.raise_for_status()

        result = response.json()
        image_url = result.get("res_url")
        restext = result.get("restext","")

        if not image_url:
            if result.get("restext"):
                # åˆ›å»ºä¸€ä¸ªçº¯ç™½è‰²çš„å›¾ç‰‡
                from PIL import Image
                white_image = Image.new("RGB", (512, 512), (255, 255, 255))
                white_tensor = ImageConverter.pil2tensor(white_image)
                return (white_tensor, result.get("restext"), conversation_history)
            else:
                raise ValueError("æ¨¡å‹æœªå›å¤")

        image_urls = image_url.split("|") if image_url else []
        conversation_history = result.get("conversation_history", [])  # æå–å¯¹è¯å†å²
        if conversation_history:
            # print(f"APIè¿”å›å¯¹è¯å†å²: {conversation_history}")
            ImageConverter.conversation_context["image"] = conversation_history
            conversation_history = {
                "image": conversation_history
            }
            # print("ContextNode ä¿å­˜å¯¹è¯å†å²:", ImageConverter.conversation_context)
        print(image_urls)
        for image_url in image_urls:
            if not image_url:
                continue
            try:
                # ä¸‹è½½å›¾ç‰‡
                response = requests.get(image_url)
                response.raise_for_status()
                # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
                from PIL import Image
                img = Image.open(BytesIO(response.content)).convert("RGB")
                output_tensors.append(ImageConverter.pil2tensor(img))
            except Exception as e:
                print(f"ä¸‹è½½å›¾ç‰‡ {image_url} å¤±è´¥: {str(e)}")
                error_tensor = ImageConverter.create_error_image("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                output_tensors.append(error_tensor)
        if not output_tensors:
            error_tensor = ImageConverter.create_error_image("æœªè·å–åˆ°æœ‰æ•ˆå›¾ç‰‡ URL")
            output_tensors.append(error_tensor)
        return (torch.cat(output_tensors, dim=0),restext,conversation_history)


class ContextNode:
    # ========== æ ¸å¿ƒå¼ºåˆ¶æ‰§è¡Œé…ç½®ï¼ˆç¼ºä¸€ä¸å¯ï¼‰ ==========
    OUTPUT_NODE = True       # æ ‡è®°ä¸ºè¾“å‡ºèŠ‚ç‚¹ï¼Œä¼˜å…ˆæ‰§è¡Œ
    FORCE_ATTN = True        # å¼ºåˆ¶ComfyUIå…³æ³¨è¯¥èŠ‚ç‚¹ï¼Œæ— è§†è¾“å‡ºæ˜¯å¦è¢«ä½¿ç”¨
    CACHEABLE = False        # ç¦ç”¨ç»“æœç¼“å­˜ï¼Œç»ä¸å¤ç”¨æ—§ç»“æœ
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            # ========== å…³é”®ï¼šåŠ ä¸€ä¸ªâ€œå¯å˜ä¼ªè¾“å…¥â€ï¼ˆseedï¼‰ï¼Œè§¦å‘èŠ‚ç‚¹é‡æ–°æ‰§è¡Œ ==========
            "required": {
                "seed": ("INT", {"default": 1, "min": 1, "max": 0xffffffffffffffff}),
            },
            # ä¿ç•™åŸæœ‰éšè—å‚æ•°
            "hidden": {
                "unique_id": "UNIQUE_ID",
                "prompt": "PROMPT"
            }
        }

    RETURN_TYPES = ("ANY",)
    RETURN_NAMES = ("context",)
    FUNCTION = "read_global_context"
    CATEGORY = "ğŸ¨MJapiparty/LLM"
    DESCRIPTION = "è¯»å–å…¨å±€å¯¹è¯ä¸Šä¸‹æ–‡å¹¶è¾“å‡ºï¼ˆå¼ºåˆ¶æ¯æ¬¡æ‰§è¡Œï¼‰"

    def read_global_context(self, seed, unique_id=None, prompt=None):
        # åˆå§‹åŒ–å®¹é”™ï¼šç¡®ä¿ImageConverteræœ‰conversation_contextå±æ€§
        if not hasattr(ImageConverter, 'conversation_context'):
            ImageConverter.conversation_context = []
        
        # è¯»å–æœ€æ–°å…¨å±€ä¸Šä¸‹æ–‡
        conversation_history = ImageConverter.conversation_context
        log_prefix = f"[ContextNode-{unique_id[:8] if unique_id else 'æœªçŸ¥'}]"
        # æ‰“å°æ—¥å¿—ï¼ˆéªŒè¯æ¯æ¬¡éƒ½æ‰§è¡Œï¼‰
        print(f"{log_prefix} æœ¬æ¬¡ä¼ å…¥Geminiçš„ä¸Šä¸‹æ–‡ï¼š{len(conversation_history)}æ¡")
        print(f"{log_prefix} æœ¬æ¬¡æ‰§è¡Œseedï¼š{seed}")  # éªŒè¯seedå˜åŒ–è§¦å‘æ‰§è¡Œ
        
        # ç¡®ä¿è¿”å›åˆæ³•åˆ—è¡¨
        return (conversation_history,)

NODE_CLASS_MAPPINGS = {
    "GeminiEditNode": GeminiEditNode,
    "NanoProNode": NanoProNode,
    "Flux2Node": Flux2Node,
    "FluxProNode": FluxProNode,
    "FluxMaxNode": FluxMaxNode,
    "ReplaceNode": ReplaceNode,
    "SeedEdit3": SeedEdit3,
    "DoubaoSeedreamNode": DoubaoSeedreamNode,
    "QwenImageNode": QwenImageNode,
    "QwenImageEditNode": QwenImageEditNode,
    "KouTuNode": KouTuNode,
    "DreaminaT2VNode": DreaminaT2VNode,
    "DreaminaI2VNode": DreaminaI2VNode,
    "GetDressing": GetDressing,
    "ViduNode": ViduNode,
    "ReplaceClothesNode": ReplaceClothesNode,
    "ModelGenNode": ModelGenNode,
    "MoterPoseNode": MoterPoseNode,
    "ViduT2VNode": ViduT2VNode,
    "ContextNode": ContextNode,
    "ViduI2VNode": ViduI2VNode,
    "ImageUpscaleNode": ImageUpscaleNode,
    "ImageTranslateNode": ImageTranslateNode,
    "FurniturePhotoNode": FurniturePhotoNode,
    "DetailPhotoNode": DetailPhotoNode,
    "DetailJinNode": DetailJinNode,
    "FurnitureAngleNode": FurnitureAngleNode, 
    "DreaminaI2INode": DreaminaI2INode,
    "GeminiLLMNode": GeminiLLMNode,
    "Gemini3NanoNode": Gemini3NanoNode,
    "FileLoaderNode": FileLoaderNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "GeminiEditNode": "Gemini-Nano-1å›¾ç‰‡ç¼–è¾‘",
    "NanoProNode": "Gemini-Nano-2-proå›¾ç‰‡ç¼–è¾‘",
    "Flux2Node": "Flux-2-pro",
    "FluxProNode": "Flux-Kontext-pro",
    "FluxMaxNode": "Flux-Kontext-max",
    "SeedEdit3": "seededit_v3.0",
    "DoubaoSeedreamNode": "seedream-v4.5",
    "QwenImageNode": "Qwen-imageæ–‡ç”Ÿå›¾",
    "QwenImageEditNode": "Qwen-image-editå›¾ç‰‡ç¼–è¾‘",
    "ReplaceNode": "Reduxè¿ç§»",
    "KouTuNode": "è‡ªåŠ¨æŠ å›¾",
    "DreaminaT2VNode": "Seedanceæ–‡ç”Ÿè§†é¢‘",
    "DreaminaI2VNode": "Seedanceå›¾ç”Ÿè§†é¢‘",
    "GetDressing": "AIæœè£…æå–",
    "ViduNode": "Viduå‚è€ƒç”Ÿè§†é¢‘",
    "ReplaceClothesNode": "AIåŒæ¬¾æœè£…æ›¿æ¢",
    "ModelGenNode": "æœè£…æ¨¡ç‰¹ç”Ÿæˆ",
    "MoterPoseNode": "æ¨¡ç‰¹å§¿åŠ¿æ›´æ”¹",
    "ViduT2VNode": "Viduæ–‡ç”Ÿè§†é¢‘",
    "ViduI2VNode": "Vidué¦–å°¾å¸§è§†é¢‘",
    "ImageUpscaleNode": "é«˜æ¸…æ”¾å¤§",
    "ImageTranslateNode": "å›¾ç‰‡ç¿»è¯‘",
    "FurniturePhotoNode": "AIå®¶å…·æ‘„å½±å›¾",
    "DetailPhotoNode": "å±€éƒ¨ç»†èŠ‚å‘ˆç°",
    "DetailJinNode": "ç»†èŠ‚ç²¾ä¿®",
    "FurnitureAngleNode": "å®¶å…·è§’åº¦å›¾",
    "DreaminaI2INode": "Dreaminaå‚è€ƒç”Ÿå›¾",
    "GeminiLLMNode": "Gemini3-LLM",
    "Gemini3NanoNode": "Gemini3-image-Nano",
    "ContextNode": "å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†",
    "FileLoaderNode": "æ–‡ä»¶åŠ è½½å™¨",
}
