import requests
from PIL import Image
from io import BytesIO
import base64
from torchvision import transforms
import numpy as np
import torch
import configparser
import os  # å¯¼å…¥ os ç”¨äºè·¯å¾„å¤„ç†

# ä» base.py å¯¼å…¥ pil2tensor å‡½æ•°
from .base import pil2tensor

class VolcPicNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset"}),
                "width": ("INT", {"default": 512}),
                "height": ("INT", {"default": 512}),
                "cfg_scale": ("FLOAT", {"default": 2.5}),
                "seed": ("INT", {"default": 1234}),
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ”¥ MJapiparty/ImageGenerate"

    def generate(self, prompt, width, height, cfg_scale, seed, batch_size):
        # è¯»å–é…ç½®æ–‡ä»¶
        config = configparser.ConfigParser()
        current_dir = os.path.dirname(os.path.abspath(__file__))
        config_path = os.path.join(os.path.dirname(current_dir), 'config.ini')
        config.read(config_path)
        
        oneapi_url = config.get('API', 'BASE_URL')
        oneapi_token = config.get('API', 'KEY')

        use_pre_llm = False
        if len(prompt) > 500:
            use_pre_llm = True

        def call_api(seed_override):
            payload = {
                "model": "volc-pic-3.0",
                "req_key": "high_aes_general_v30l_zt2i",
                "prompt": prompt,
                "width": width,
                "use_pre_llm": use_pre_llm,
                "height": height,
                "cfg_scale": cfg_scale,
                "seed": int(seed_override)
            }
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            result = response.json()
            img_base64_list = result.get('data', {}).get('binary_data_base64', [])
            if not img_base64_list:
                raise ValueError("Empty image data from API.")
            img_data = img_base64_list[0]
            img_bytes = base64.b64decode(img_data)
            img = Image.open(BytesIO(img_bytes)).convert("RGB")
            return img

        output_tensors = []

        try:
            for i in range(batch_size):
                # å¦‚æœä¸¤æ¬¡è¯·æ±‚ç”¨åŒä¸€ä¸ªseedä¹Ÿè¡Œï¼Œå¯æ”¹ä¸º seed+i å®ç°ä¸åŒseed
                img = call_api(seed + i)
                # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
                tensor_img = pil2tensor(img)
                output_tensors.append(tensor_img)
                print(f"ğŸ”¥ VolcPicNode ç¬¬ {i+1} å¼ å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {prompt} ({width}x{height})")

            return (torch.cat(output_tensors, dim=0),)  # æ‹¼æ¥ä¸º (æ•°é‡, H, W, 3)

        except Exception as e:
            print(f"ğŸ”¥ VolcPicNode é”™è¯¯: {str(e)}")
            error_img = Image.new("RGB", (width, height), (255, 0, 0))
            # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
            error_tensor = pil2tensor(error_img)
            # è¿”å›æŒ‡å®šæ•°é‡é”™è¯¯å›¾
            error_tensors = [error_tensor for _ in range(batch_size)]
            return (torch.cat(error_tensors, dim=0),)

class DreaminaI2INode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                # "image": ("STRING", {"default": "https://pic.52112.com/180320/180320_17/Bl3t6ivHKZ_small.jpg"}),
                "prompt": ("STRING", {"default": ""}),
                "width": ("INT", {"default": 1024}),
                "height": ("INT", {"default": 1024}),
                "gpen": ("FLOAT", {"default": 0.4}),
                "skin": ("FLOAT", {"default": 0.3}),
                "skin_unifi": ("FLOAT", {"default": 0.0}),
                "gen_mode": (["creative", "reference", "reference_char"], {"default": "reference"}),
                "seed": ("INT", {"default": -1}),  # -1è¡¨ç¤ºéšæœº
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # ç”Ÿæˆå¼ æ•°
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("output",)
    FUNCTION = "generate"
    CATEGORY = "Dreamina"

    def tensor2pil(self, tensor):
        # Tensor (1, H, W, 3) to PIL
        image = tensor.squeeze().numpy() * 255.0
        return Image.fromarray(image.astype(np.uint8))

    def generate(self, image, prompt, width, height, gpen, skin, skin_unifi, gen_mode, seed, batch_size):
        # è¯»å–é…ç½®æ–‡ä»¶
        config = configparser.ConfigParser()
        current_dir = os.path.dirname(os.path.abspath(__file__))
        config_path = os.path.join(os.path.dirname(current_dir), 'config.ini')
        config.read(config_path)
        
        oneapi_url = config.get('API', 'BASE_URL')
        oneapi_token = config.get('API', 'KEY')

        # Convert input tensor to base64
        pil_image = self.tensor2pil(image)
        buffered = BytesIO()
        pil_image.save(buffered, format="JPEG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }

        output_tensors = []

        for i in range(batch_size):  # batch_size=2 æ—¶è°ƒç”¨ä¸¤æ¬¡
            payload = {
                "model": "volc-pic-3.0",
                "req_key": "i2i_portrait_photo",
                "prompt": prompt,
                "width": width,
                "height": height,
                "gpen": gpen,
                "skin": skin,
                "skin_unifi": skin_unifi,
                "gen_mode": gen_mode,
                "seed": None if seed == -1 else seed + i,  # é¿å…å®Œå…¨ä¸€æ ·
                "batch_size": 1,  
                "image_base64": img_base64
            }

            try:
                response = requests.post(oneapi_url, headers=headers, json=payload, timeout=120)
                response.raise_for_status()
                result = response.json()
                img_base64_list = result.get('data', {}).get('binary_data_base64', [])

                if not img_base64_list:
                    raise ValueError("APIè¿”å›ç©ºå›¾åƒæ•°æ®.")

                # æ­£å¸¸æƒ…å†µä¸‹æ¯æ¬¡è¿”å›1å¼ 
                img_bytes = base64.b64decode(img_base64_list[0])
                img = Image.open(BytesIO(img_bytes)).convert("RGB")
                # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
                tensor_img = pil2tensor(img)
                output_tensors.append(tensor_img)

                print(f"âœ… DreaminaI2INode ç¬¬{i+1}æ¬¡è°ƒç”¨æˆåŠŸ")

            except Exception as e:
                print(f"âŒ DreaminaI2INode é”™è¯¯(ç¬¬{i+1}æ¬¡): {str(e)}")
                error_img = Image.new("RGB", (width, height), (255, 0, 0))
                # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
                error_tensor = pil2tensor(error_img)
                output_tensors.append(error_tensor)

        return (torch.cat(output_tensors, dim=0),)  # è¿”å›(batch_size, H, W, 3)



NODE_CLASS_MAPPINGS = {
    "DreaminaI2INode": DreaminaI2INode,
     "Dreamina t2i": VolcPicNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "DreaminaI2INode": "ğŸ¨ Dreamina i2iï¼ˆæ¢¦å›¾ç”Ÿå›¾ï¼‰",
    "VolcPicNode": "Dreamina t2i"
}
