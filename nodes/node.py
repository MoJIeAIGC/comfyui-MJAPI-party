import requests
from PIL import Image
from io import BytesIO
import base64
from torchvision import transforms
import numpy as np
import torch
import os
from comfy_api.input_impl.video_types import VideoFromFile

from .base import ImageConverter
from .config import ConfigManager
import random
# åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
config_manager = ConfigManager()


class DreaminaI2INode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                # "image": ("STRING", {"default": "https://pic.52112.com/180320/180320_17/Bl3t6ivHKZ_small.jpg"}),
                "prompt": ("STRING", {"default": "", "multiline": True}),
                "width": ("INT", {"default": 1024}),
                "height": ("INT", {"default": 1024}),
                "gpen": ("FLOAT", {"default": 0.4}),
                "skin": ("FLOAT", {"default": 0.3}),
                "skin_unifi": ("FLOAT", {"default": 0.0}),
                "gen_mode": (["creative", "reference", "reference_char"], {"default": "reference"}),
                "seed": ("INT", {"default": -1}),  # -1è¡¨ç¤ºéšæœº
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # ç”Ÿæˆå¼ æ•°
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("output",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Dreamina(å³æ¢¦)"

    def generate(self, image, prompt, width, height, gpen, skin, skin_unifi, gen_mode, seed, batch_size):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        # Convert input tensor to base64
        pil_image = ImageConverter.tensor2pil(image)
        buffered = BytesIO()
        pil_image.save(buffered, format="JPEG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }

        output_tensors = []

        for i in range(batch_size):  # batch_size=2 æ—¶è°ƒç”¨ä¸¤æ¬¡
            payload = {
                "model": "volc-pic-3.0",
                "req_key": "i2i_portrait_photo",
                "prompt": prompt,
                "width": width,
                "height": height,
                "gpen": gpen,
                "skin": skin,
                "skin_unifi": skin_unifi,
                "gen_mode": gen_mode,
                "seed": seed+i,  # é¿å…å®Œå…¨ä¸€æ ·
                "batch_size": 1,  
                "image_base64": img_base64
            }

            try:
                response = requests.post(oneapi_url, headers=headers, json=payload, timeout=120)
                # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
                if response.status_code != 200:
                    error_msg = ImageConverter.get_status_error_msg(response,1)
                    error_tensor = ImageConverter.create_error_image(error_msg)
                    output_tensors.append(error_tensor)
                    continue
                response.raise_for_status()
                result = response.json()
                img_base64_list = result.get('data', {}).get('binary_data_base64', [])

                if not img_base64_list:
                    raise ValueError("APIè¿”å›ç©ºå›¾åƒæ•°æ®.")

                # æ­£å¸¸æƒ…å†µä¸‹æ¯æ¬¡è¿”å›1å¼ 
                img_bytes = base64.b64decode(img_base64_list[0])
                img = Image.open(BytesIO(img_bytes)).convert("RGB")
                # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
                tensor_img = ImageConverter.pil2tensor(img)
                output_tensors.append(tensor_img)

                print(f"âœ… DreaminaI2INode ç¬¬{i+1}æ¬¡è°ƒç”¨æˆåŠŸ")

            except Exception as e:
                print(f"âŒ DreaminaI2INode é”™è¯¯(ç¬¬{i+1}æ¬¡): {str(e)}")
                error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
                output_tensors.append(error_tensor)

        return (torch.cat(output_tensors, dim=0),)  # è¿”å›(batch_size, H, W, 3)

class FluxProNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "seed": ("INT", {"default": -1}),
                "is_translation": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "aspect_ratio": (["default", "1:1", "3:4", "4:3", "9:16", "16:9"], {"default": "default"}),
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
            },
            "optional": {
                "image_input": ("IMAGE", {"default": None}),  # å¯é€‰çš„å›¾åƒè¾“å…¥
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Flux"

    def generate(self, prompt, seed, batch_size, image_input=None, is_translation=False, aspect_ratio="default"):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        print(f"Flux API URL: {oneapi_url}")  # æ‰“å°API URL

        # å¦‚æœæä¾›äº†å›¾åƒè¾“å…¥ï¼Œå°†å…¶è½¬æ¢ä¸ºbase64
        image_base64 = None
        if image_input is not None:
            try:
                pil_image = ImageConverter.tensor2pil(image_input)
                buffered = BytesIO()
                pil_image.save(buffered, format="JPEG")
                img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
                image_base64 = img_base64
            except Exception as e:
                print(f"å¤„ç†å›¾åƒå¤±è´¥: {e}")
                image_base64 = None

        def call_api(seed_override):
            payload = {
                "model": "flux-context-pro",
                "safety_tolerance":6,
                "prompt": prompt,
                "seed": int(seed_override),
                "is_translation": is_translation,  # ä¼ é€’ç¿»è¯‘æ¨¡å¼å‚æ•°
            }
            # å¦‚æœæœ‰å›¾åƒè¾“å…¥ï¼ŒåŠ å…¥åˆ°payloadä¸­
            if image_base64 is not None:
                payload["input_image"] = image_base64
            if aspect_ratio != "default":
                payload["aspect_ratio"] = aspect_ratio
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                error_tensor = ImageConverter.create_error_image(error_msg, width=512, height=512)
                return error_tensor
            response.raise_for_status()
            result = response.json()

            # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
            image_url = result['result'].get('sample', None)
            if not image_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(image_url)
            response.raise_for_status()
            # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
            img = Image.open(BytesIO(response.content)).convert("RGB")
            return ImageConverter.pil2tensor(img)

        output_tensors = []

        try:
            for i in range(batch_size):
                # å¦‚æœä¸¤æ¬¡è¯·æ±‚ç”¨åŒä¸€ä¸ªseedä¹Ÿè¡Œï¼Œå¯æ”¹ä¸º seed+i å®ç°ä¸åŒseed
                img = call_api(seed + i)
                # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
                # tensor_img = ImageConverter.pil2tensor(img)
                output_tensors.append(img)
                print(f"Flux ç¬¬ {i+1} å¼ å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {prompt}")

            return (torch.cat(output_tensors, dim=0),)  # æ‹¼æ¥ä¸º (æ•°é‡, H, W, 3)

        except Exception as e:
            print(f"Fluxé”™è¯¯: {str(e)}")
            error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
            # è¿”å›æŒ‡å®šæ•°é‡é”™è¯¯å›¾
            error_tensors = [error_tensor for _ in range(batch_size)]
            return (torch.cat(error_tensors, dim=0),)

class FluxMaxNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "seed": ("INT", {"default": -1}),
                "is_translation": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "aspect_ratio": (["default", "1:1", "3:4", "4:3", "9:16", "16:9"], {"default": "default"}),
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
            },
            "optional": {
                "image_input": ("IMAGE", {"default": None}),  # å¯é€‰çš„å›¾åƒè¾“å…¥
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Flux"

    def generate(self, prompt, seed, batch_size, image_input=None, is_translation=False, aspect_ratio="default"):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        print(f"Flux API URL: {oneapi_url}")  # æ‰“å°API URL

        # å¦‚æœæä¾›äº†å›¾åƒè¾“å…¥ï¼Œå°†å…¶è½¬æ¢ä¸ºbase64
        image_base64 = None
        if image_input is not None:
            try:
                pil_image = ImageConverter.tensor2pil(image_input)
                buffered = BytesIO()
                pil_image.save(buffered, format="JPEG")
                img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
                image_base64 = img_base64
            except Exception as e:
                print(f"å¤„ç†å›¾åƒå¤±è´¥: {e}")
                image_base64 = None

        def call_api(seed_override):
            payload = {
                "model": "flux-context-max",
                "safety_tolerance":6,
                "prompt": prompt,
                "seed": int(seed_override),
                "is_translation": is_translation,  # ä¼ é€’ç¿»è¯‘æ¨¡å¼å‚æ•°
            }
            # å¦‚æœæœ‰å›¾åƒè¾“å…¥ï¼ŒåŠ å…¥åˆ°payloadä¸­
            if image_base64 is not None:
                payload["input_image"] = image_base64
            if aspect_ratio != "default":
                payload["aspect_ratio"] = aspect_ratio
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=1200)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                error_tensor = ImageConverter.create_error_image(error_msg, width=512, height=512)
                return error_tensor
            response.raise_for_status()
            result = response.json()

            # ä»è¿”å›çš„ç»“æœä¸­æå–å›¾ç‰‡ URL
            image_url = result['result'].get('sample', None)
            if not image_url:
                raise ValueError("æœªæ‰¾åˆ°å›¾ç‰‡ URL")
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(image_url)
            response.raise_for_status()
            # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
            img = Image.open(BytesIO(response.content)).convert("RGB")
            return ImageConverter.pil2tensor(img)

        output_tensors = []

        try:
            for i in range(batch_size):
                # å¦‚æœä¸¤æ¬¡è¯·æ±‚ç”¨åŒä¸€ä¸ªseedä¹Ÿè¡Œï¼Œå¯æ”¹ä¸º seed+i å®ç°ä¸åŒseed
                img = call_api(seed + i)
                # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
                # tensor_img = ImageConverter.pil2tensor(img)
                output_tensors.append(img)
                print(f"Flux ç¬¬ {i+1} å¼ å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {prompt}")

            return (torch.cat(output_tensors, dim=0),)  # æ‹¼æ¥ä¸º (æ•°é‡, H, W, 3)

        except Exception as e:
            print(f"Fluxé”™è¯¯: {str(e)}")
            error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
            # è¿”å›æŒ‡å®šæ•°é‡é”™è¯¯å›¾
            error_tensors = [error_tensor for _ in range(batch_size)]
            return (torch.cat(error_tensors, dim=0),)



class ReplaceNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "migrate_image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "migrate_mask": ("MASK",),  # è¾“å…¥é®ç½©
                "Product_image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "prompt": ("STRING", {"default": "", "multiline": True}),
                "strong": ("FLOAT", {"default": 0.6}),
                "seed": ("INT", {"default": -1}),  # -1è¡¨ç¤ºéšæœº
            },
            "optional": {
                "Product_mask": ("MASK",),  # å¯é€‰çš„å›¾åƒè¾“å…¥
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("output",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Tools_api"

    def generate(self, Product_image, prompt, migrate_image, seed, strong , Product_mask=None, migrate_mask=None):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        pro_base64 = ImageConverter.merge_image(Product_image, Product_mask)
        mig_base64 = ImageConverter.merge_image(migrate_image, migrate_mask)

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }

        output_tensors = []
        prompt = "This is a collage pictureï¼Œin the left Objects replaces the Objects in the right picture." + prompt

        payload = {
            "model": "Product_migrate_mjAPI",
            "prompt": prompt,
            "strong": strong,
            "seed": seed, 
            "image": pro_base64,
            "imagem": mig_base64
        }

        try:
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=300)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                error_tensor = ImageConverter.create_error_image(error_msg)
                output_tensors.append(error_tensor)
                raise requests.exceptions.HTTPError(f"Request failed with status code {response.status_code}: {error_msg}")
            response.raise_for_status()
            result = response.json()
            result_url = result.get('data')[0].get('fileUrl')

            if not result_url:
                raise ValueError("APIè¿”å›ç©ºå›¾åƒæ•°æ®.")

            responseurl = requests.get(result_url)
            if responseurl.status_code != 200:
                raise ValueError("ä» URL è·å–å›¾ç‰‡å¤±è´¥ã€‚")
            
            img_bytes = responseurl.content
            img = Image.open(BytesIO(img_bytes)).convert("RGB")
            # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
            tensor_img = ImageConverter.pil2tensor(img)
            output_tensors.append(tensor_img)

            print(f"âœ… ReplaceNode è°ƒç”¨æˆåŠŸ")

        except Exception as e:
            print(f"âŒ ReplaceNode é”™è¯¯: {str(e)}")
            # error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
            # output_tensors.append(error_tensor)
        return (torch.cat(output_tensors, dim=0),)  # è¿”å›(batch_size, H, W, 3)


class SeedEdit3:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "prompt": ("STRING", {"default": "", "multiline": True}),
                "cfg_scale": ("FLOAT", {"default": 0.5}),
                "seed": ("INT", {"default": -1}),  # -1è¡¨ç¤ºéšæœº
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # ç”Ÿæˆå¼ æ•°
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("output",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/seededit_v3.0"

    def generate(self, image, prompt, cfg_scale, seed, batch_size):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        # Convert input tensor to base64
        pil_image = ImageConverter.tensor2pil(image)
        buffered = BytesIO()
        pil_image.save(buffered, format="JPEG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }

        output_tensors = []

        for i in range(batch_size):  # batch_size=2 æ—¶è°ƒç”¨ä¸¤æ¬¡
            payload = {
                "model": "seededit_v3.0",
                "req_key": "seededit_v3.0",
                "prompt": prompt,
                "scale": cfg_scale,
                "seed": seed+i,  # é¿å…å®Œå…¨ä¸€æ ·
                "batch_size": 1,  
                "image_base64": img_base64
            }

            try:
                response = requests.post(oneapi_url, headers=headers, json=payload, timeout=120)
                # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
                if response.status_code != 200:
                    error_msg = ImageConverter.get_status_error_msg(response,1)
                    error_tensor = ImageConverter.create_error_image(error_msg)
                    output_tensors.append(error_tensor)
                    continue
                response.raise_for_status()
                result = response.json()
                img_base64_list = result.get('data', {}).get('binary_data_base64', [])

                if not img_base64_list:
                    raise ValueError("APIè¿”å›ç©ºå›¾åƒæ•°æ®.")

                # æ­£å¸¸æƒ…å†µä¸‹æ¯æ¬¡è¿”å›1å¼ 
                img_bytes = base64.b64decode(img_base64_list[0])
                img = Image.open(BytesIO(img_bytes)).convert("RGB")
                # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
                tensor_img = ImageConverter.pil2tensor(img)
                output_tensors.append(tensor_img)

                print(f"âœ… seededit_v3.0 ç¬¬{i+1}æ¬¡è°ƒç”¨æˆåŠŸ")

            except Exception as e:
                print(f"âŒ seededit_v3.0 é”™è¯¯(ç¬¬{i+1}æ¬¡): {str(e)}")
                error_tensor = ImageConverter.create_error_image("è¿è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
                output_tensors.append(error_tensor)

        return (torch.cat(output_tensors, dim=0),)  # è¿”å›(batch_size, H, W, 3)


class KouTuNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "seed": ("INT", {"default": -1}),  # -1è¡¨ç¤ºéšæœº
            },
            "optional": {
                "mask": ("MASK",),  # å¯é€‰çš„å›¾åƒè¾“å…¥
            }

        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("output",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Tools_api"

    def generate(self,  image, seed,  mask=None):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        mig_base64 = ImageConverter.merge_image(image, mask)

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }

        output_tensors = []

        payload = {
            "model": "auto_koutu_1.0",
            "seed": seed, 
            "imagem": mig_base64
        }

        try:
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=300)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                error_tensor = ImageConverter.create_error_image(error_msg)
                output_tensors.append(error_tensor)
                raise requests.exceptions.HTTPError(f"Request failed with status code {response.status_code}: {error_msg}")
            response.raise_for_status()
            result = response.json()
            result_url = result.get('data')[0].get('fileUrl')

            if not result_url:
                raise ValueError("APIè¿”å›ç©ºå›¾åƒæ•°æ®.")

            responseurl = requests.get(result_url)
            if responseurl.status_code != 200:
                raise ValueError("ä» URL è·å–å›¾ç‰‡å¤±è´¥ã€‚")
            
            img_bytes = responseurl.content
            img = Image.open(BytesIO(img_bytes)).convert("RGBA")
            # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
            tensor_img = ImageConverter.pil2tensor(img)
            output_tensors.append(tensor_img)

            print(f"âœ… KouTuNode è°ƒç”¨æˆåŠŸ")

        except Exception as e:
            print(f"âŒ KouTuNode é”™è¯¯: {str(e)}")
        return (torch.cat(output_tensors, dim=0),)  # è¿”å›(batch_size, H, W, 3)


class DreaminaT2VNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "aspect_ratio": (["default", "1:1", "3:4", "4:3", "9:16", "16:9", "21:9"], {"default": "default"}),
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("VIDEO",)  # è¿”å›VIDEOç±»å‹
    RETURN_NAMES = ("video",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Dreamina(å³æ¢¦)"

    def generate(self, prompt, seed, aspect_ratio="default"):
        # è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        def call_api(seed_override):
            payload = {
                "model": "Dreaminat2vNode",
                "req_key": "jimeng_vgfm_t2v_l20",
                "prompt": prompt,
                "seed": int(seed_override)
            }
            if aspect_ratio != "default":
                payload["aspect_ratio"] = aspect_ratio
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=240)

            response.raise_for_status()

            result = response.json()
            print(result)

            video_url = result.get('data', {}).get('video_url', [])
            if not video_url:
                raise ValueError("Empty video data from API.")
            return video_url

        video_url = call_api(seed)
        print(video_url)
        # ä¸‹è½½è§†é¢‘å¹¶æå–å¸§
        video_path = ImageConverter.download_video(video_url)
        # ä½¿ç”¨ VideoFromFile å°è£…è§†é¢‘

        return (VideoFromFile(video_path),)


class DreaminaI2VNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "aspect_ratio": (["default", "1:1", "3:4", "4:3", "9:16", "16:9", "21:9"], {"default": "default"}),
                "seed": ("INT", {"default": -1}),
                "images": ("IMAGE", {"default": []})  # æ¥æ”¶å¤šä¸ªå›¾ç‰‡
            }
        }

    RETURN_TYPES = ("VIDEO",)  # è¿”å›VIDEOç±»å‹
    RETURN_NAMES = ("video",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Dreamina(å³æ¢¦)"

    def generate(self, prompt, seed, aspect_ratio="default", images=[]):
        # è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        def call_api(seed_override, binary_data_base64):
            payload = {
                "model": "DreaminaI2VNode",
                "req_key": "jimeng_vgfm_i2v_l20",
                "prompt": prompt,
                "seed": int(seed_override),
                "binary_data_base64": binary_data_base64  # æ·»åŠ Base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
            }
            if aspect_ratio != "default":
                payload["aspect_ratio"] = aspect_ratio
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=240)

            response.raise_for_status()

            result = response.json()
            print(result)

            video_url = result.get('data', {}).get('video_url', [])
            if not video_url:
                raise ValueError("Empty video data from API.")
            return video_url

        # å°†å›¾åƒè½¬æ¢ä¸ºBase64ç¼–ç 
        binary_data_base64 = ImageConverter.convert_images_to_base64(images)

        # è°ƒç”¨API
        video_url = call_api(seed, binary_data_base64)
        print(video_url)
        # ä¸‹è½½è§†é¢‘å¹¶æå–å¸§
        video_path = ImageConverter.download_video(video_url)
        # ä½¿ç”¨ VideoFromFile å°è£…è§†é¢‘

        return (VideoFromFile(video_path),)


class QwenImageNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "A beautiful sunset", "multiline": True}),
                "size": (["1328*1328", "1664*928", "1472*1140", "1140*1472", "928*1664"], {"default": "1328*1328"}),
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
                "prompt_extend": ("BOOLEAN", {"default": False}),  # æ˜¯å¦æ˜¯ç¿»è¯‘æ¨¡å¼
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/qwen-image"

    def generate(self, prompt, size, batch_size,seed,prompt_extend):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        def call_api():
            payload = {
                "model": "qwen-image",
                "modelr": "qwen-image",
                "prompt": prompt,
                "prompt_extend": prompt_extend,
                "size": size,
            }
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=60)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response,1)
                error_tensor = ImageConverter.create_error_image(error_msg, 512, 512)
                return error_tensor

            response.raise_for_status()
            result = response.json()
            # å¤„ç†URLåˆ—è¡¨è·å–å›¾ç‰‡æ•°æ®
            img_bytes_list = []
            url = result.get('output').get('results', [])[0].get('url', None)
            response = requests.get(url)
            response.raise_for_status()
            img_bytes_list.append(response.content)
            
            # è½¬æ¢ä¸ºBase64æ ¼å¼
            img_base64_list = [base64.b64encode(img_bytes).decode('utf-8') for img_bytes in img_bytes_list]
            img_data = img_base64_list[0]  # å–ç¬¬ä¸€å¼ å›¾ç‰‡
            img_bytes = base64.b64decode(img_data)
            img = Image.open(BytesIO(img_bytes)).convert("RGB")
            return ImageConverter.pil2tensor(img)

        output_tensors = []

        try:
            for i in range(batch_size):
                img_tensor = call_api()
                if isinstance(img_tensor, torch.Tensor):
                    # åˆ¤æ–­æ˜¯å¦ä¸ºé”™è¯¯å›¾åƒ tensor
                    if img_tensor.shape[1] == 512 and img_tensor.shape[2] == 512 and img_tensor[0, 0, 0, 0] == 1:
                        return (img_tensor,)
                output_tensors.append(img_tensor)
                print(f"QwenImageNode ç¬¬ {i+1} å¼ å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {prompt} ()")

            return (torch.cat(output_tensors, dim=0),)  # æ‹¼æ¥ä¸º (æ•°é‡, H, W, 3)

        except Exception as e:
            print(f"QwenImageNode é”™è¯¯: {str(e)}")
            error_tensor = ImageConverter.create_error_image(str(e))
            error_tensors = [error_tensor for _ in range(batch_size)]
            return (torch.cat(error_tensors, dim=0),)


class QwenImageEditNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "", "multiline": True}),
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 2}),  # æ–°å¢å‚æ•°ï¼Œåªèƒ½æ˜¯1æˆ–2
                "seed": ("INT", {"default": -1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)  # è¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªIMAGE
    RETURN_NAMES = ("output",)  # ä¿æŒä¸ºä¸€ä¸ªè¿”å›å
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/qwen-image-edit"

    def generate(self, prompt,image, batch_size,seed):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        image_base64 = ImageConverter.tensor_to_base64(image)

        def call_api():
            payload = {
                "model": "qwen-image-edit",
                "prompt": prompt,
                "image": image_base64,
            }
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {oneapi_token}"
            }
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=60)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response,1)
                error_tensor = ImageConverter.create_error_image(error_msg, 512, 512)
                return error_tensor

            response.raise_for_status()
            result = response.json()
            # å¤„ç†URLåˆ—è¡¨è·å–å›¾ç‰‡æ•°æ®
            img_bytes_list = []
            url = result.get('output', {}).get('choices', [{}])[0].get('message', {}).get('content', [{}])[0].get('image', None)
            response = requests.get(url)
            response.raise_for_status()
            img_bytes_list.append(response.content)
            
            # è½¬æ¢ä¸ºBase64æ ¼å¼
            img_base64_list = [base64.b64encode(img_bytes).decode('utf-8') for img_bytes in img_bytes_list]
            img_data = img_base64_list[0]  # å–ç¬¬ä¸€å¼ å›¾ç‰‡
            img_bytes = base64.b64decode(img_data)
            img = Image.open(BytesIO(img_bytes)).convert("RGB")
            return ImageConverter.pil2tensor(img)

        output_tensors = []

        try:
            for i in range(batch_size):
                img_tensor = call_api()
                if isinstance(img_tensor, torch.Tensor):
                    # åˆ¤æ–­æ˜¯å¦ä¸ºé”™è¯¯å›¾åƒ tensor
                    if img_tensor.shape[1] == 512 and img_tensor.shape[2] == 512 and img_tensor[0, 0, 0, 0] == 1:
                        return (img_tensor,)
                output_tensors.append(img_tensor)
                print(f"QwenImageNode ç¬¬ {i+1} å¼ å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {prompt} ()")

            return (torch.cat(output_tensors, dim=0),)  # æ‹¼æ¥ä¸º (æ•°é‡, H, W, 3)

        except Exception as e:
            print(f"QwenImageNode é”™è¯¯: {str(e)}")
            error_tensor = ImageConverter.create_error_image(str(e))
            error_tensors = [error_tensor for _ in range(batch_size)]
            return (torch.cat(error_tensors, dim=0),)


class GetDressing:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "prompt": ("STRING", {"default": "Extract the clothes", "multiline": True}),
                "seed": ("INT", {"default": -1}),  # -1è¡¨ç¤ºéšæœº
                "prompt_extend": ("BOOLEAN", {"default": True}), 
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("output",)
    FUNCTION = "generate"
    CATEGORY = "ğŸ¨MJapiparty/Tools_api"

    def generate(self,  image, seed,  prompt, prompt_extend):
        # è°ƒç”¨é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        oneapi_url, oneapi_token = config_manager.get_api_config()

        mig_base64 = ImageConverter.tensor_to_base64(image)

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {oneapi_token}"
        }

        output_tensors = []
        if seed == -1:
            seed = random.randint(0, 999999)


        payload = {
            "model": "mojie_get_dressing",
            "seed": seed, 
            "image": mig_base64,
        }
        
        if not prompt_extend:
            payload["prompt"] = prompt
        

        try:
            response = requests.post(oneapi_url, headers=headers, json=payload, timeout=300)
            # åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦ä¸º 200
            if response.status_code != 200:
                error_msg = ImageConverter.get_status_error_msg(response)
                error_tensor = ImageConverter.create_error_image(error_msg)
                output_tensors.append(error_tensor)
                raise requests.exceptions.HTTPError(f"Request failed with status code {response.status_code}: {error_msg}")
            response.raise_for_status()
            result = response.json()
            result_url = result.get('data')[0].get('fileUrl')

            if not result_url:
                raise ValueError("APIè¿”å›ç©ºå›¾åƒæ•°æ®.")

            responseurl = requests.get(result_url)
            if responseurl.status_code != 200:
                raise ValueError("ä» URL è·å–å›¾ç‰‡å¤±è´¥ã€‚")
            
            img_bytes = responseurl.content
            img = Image.open(BytesIO(img_bytes)).convert("RGBA")
            # ç›´æ¥è°ƒç”¨å¯¼å…¥çš„ pil2tensor å‡½æ•°
            tensor_img = ImageConverter.pil2tensor(img)
            output_tensors.append(tensor_img)

            print(f"âœ… GetDressing è°ƒç”¨æˆåŠŸ")

        except Exception as e:
            print(f"âŒ GetDressing é”™è¯¯: {str(e)}")
        return (torch.cat(output_tensors, dim=0),)  # è¿”å›(batch_size, H, W, 3)


NODE_CLASS_MAPPINGS = {
    "DreaminaI2INode": DreaminaI2INode,
    "FluxProNode": FluxProNode,
    "FluxMaxNode": FluxMaxNode,
    "ReplaceNode": ReplaceNode,
    "SeedEdit3": SeedEdit3,
    "KouTuNode": KouTuNode,
    "DreaminaT2VNode": DreaminaT2VNode,
    "DreaminaI2VNode": DreaminaI2VNode,
    "QwenImageNode": QwenImageNode,
    "QwenImageEditNode": QwenImageEditNode,
    "GetDressing": GetDressing,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "DreaminaI2INode": "Dreamina_I2i(å³æ¢¦)",
    "FluxProNode": "Flux-Kontext-pro",
    "FluxMaxNode": "Flux-Kontext-max",
    "ReplaceNode": "Reduxè¿ç§»",
    "SeedEdit3": "seededit_v3.0",
    "KouTuNode": "è‡ªåŠ¨æŠ å›¾",
    "DreaminaT2VNode": "å³æ¢¦æ–‡ç”Ÿè§†é¢‘",
    "DreaminaI2VNode": "å³æ¢¦å›¾ç”Ÿè§†é¢‘",
    "QwenImageNode": "qwen-imageæ–‡ç”Ÿå›¾",
    "QwenImageEditNode": "qwen-image-editå›¾ç‰‡ç¼–è¾‘",
    "GetDressing": "AIæœè£…æå–",
}
